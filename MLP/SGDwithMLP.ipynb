{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nam-gu/MLB_Prediction/blob/main/MLP/SGDwithMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7HShDFrFnL9",
        "outputId": "60255bd1-9b0e-4647-b89c-2a692eebf273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "0        0.991657\n",
            "1        1.006489\n",
            "2        1.012793\n",
            "3        0.982228\n",
            "4        0.980585\n",
            "           ...   \n",
            "24292    0.868982\n",
            "24293    0.861661\n",
            "24294    0.959000\n",
            "24295    0.905446\n",
            "24296    0.856214\n",
            "Name: Attendence, Length: 24297, dtype: float64\n",
            "0          NaN\n",
            "1        0.992\n",
            "2        1.006\n",
            "3        1.013\n",
            "4        0.982\n",
            "         ...  \n",
            "24292    0.934\n",
            "24293    0.869\n",
            "24294    0.862\n",
            "24295    0.959\n",
            "24296    0.905\n",
            "Name: 1d_home_attendance, Length: 24297, dtype: float64\n",
            "H\n",
            "OBP\n",
            "SLG\n",
            "ISO\n",
            "Babip\n",
            "RC\n",
            "K\n",
            "BB\n",
            "RBI\n",
            "K/B\n",
            "HR\n",
            "PitH\n",
            "PitOBP\n",
            "PitSLG\n",
            "PitOPS\n",
            "PitHR\n",
            "ERA\n",
            "PitB\n",
            "PitK\n",
            "PitK/B\n",
            "WHIP\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 24464 entries, 0 to 24463\n",
            "Columns: 133 entries, Date to WHIP\n",
            "dtypes: bool(2), datetime64[ns](1), float64(111), int64(15), object(4)\n",
            "memory usage: 24.7+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file = 'drive/MyDrive/data/Retrosheet_2010_2019/2010_to_2019_seasons.csv'\n",
        "game_df = pd.read_csv(file)\n",
        "\n",
        "game_col_del = '''VisitorGDP,VisitorCI,HomeGDP,HomeCI, DoubleHeader, DayOfWeek, VisitingTeamLeague, HomeTeamLeague, DayNight, CompletionInfo,ForfeitInfo, ProtestInfo,Duration, VisitorLineScore, HomeLineScore, UmpireHID, UmpireHName, Umpire1BID, Umpire1BName, Umpire2BID,Umpire2BName, Umpire3BID, Umpire3BName, UmpireLFID, UmpireLFName, UmpireRFID,UmpireRFName, VisitorManagerID, VisitorManagerName, HomeManagerID, HomeManagerName,WinningPitcherID, WinningPitcherName, LosingPitcherID, LosingPitcherNAme,SavingPitcherID, SavingPitcherName, GameWinningRBIID, GameWinningRBIName, VisitorBatting1Position, VisitorBatting2Position, VisitorBatting3Position,VisitorBatting4Position, VisitorBatting5Position, VisitorBatting6Position,VisitorBatting7Position, VisitorBatting8Position, VisitorBatting9Position,HomeBatting1Position, HomeBatting2Position, HomeBatting3Position,HomeBatting4Position, HomeBatting5Position, HomeBatting6Position,HomeBatting7Position, HomeBatting8Position, HomeBatting9Position,AdditionalInfo, AcquisitionInfo'''\n",
        "game_col_del = game_col_del.replace(\" \", \"\")\n",
        "game_col_del = game_col_del.split(\",\")\n",
        "\n",
        "game_df.drop(game_col_del,axis=1,inplace=True)\n",
        "\n",
        "my_attendence={'BOS':37755, 'LAA':45517, 'CWS':40615, 'KC':37903, 'OAK':56782, 'TEX':40300, 'ARI':48686, 'ATL':41084, 'CIN':42319,\n",
        "       'HOU':41168, 'MIL':41900, 'NYM':41922, 'PIT':38747, 'WAS':41339, 'TB':42735, 'BAL':44970, 'DET':41083, 'COL':50144,\n",
        "       'MIA':37442, 'SF':41265, 'CLE':34830, 'MIN':38544, 'SEA':47929, 'TOR':49282, 'CHC':41649, 'PHI':42792, 'SD':40209, 'STL':45494,\n",
        "       'NYY':54251, 'LAD':56000}\n",
        "# Had an extra team due to the Marlins having two different labels. Updating their team name to MIA\n",
        "game_df.replace(to_replace='FLO', value='MIA', inplace=True)\n",
        "\n",
        "# Updating game_df so team abbreviations match. Will be leveraged when aggregating teams stats\n",
        "game_df.replace(to_replace={\"NYA\":\"NYY\", \"SDN\":\"SD\", \"CHN\":\"CHC\", \"SLN\":\"STL\", \"SFN\":\"SF\", \"LAN\":\"LAD\", \"TBA\":\"TB\", \"KCA\":\"KC\", \"CHA\":\"CWS\", \"ANA\":\"LAA\", \"NYN\":\"NYM\"}, inplace=True)\n",
        "\n",
        "for key, value in my_attendence.items():\n",
        "  game_df.loc[game_df['HomeTeam']==key,'Attendence']=game_df.loc[game_df['HomeTeam']==key,'Attendence']/value\n",
        "\n",
        "\n",
        "file4 = 'drive/MyDrive/data/park_factors.csv'\n",
        "parkfactor_df = pd.read_csv(file4, encoding='cp949')\n",
        "parkfactor_df\n",
        "\n",
        "# Had an extra team due to the Marlins having two different labels. Updating their team name to MIA\n",
        "parkfactor_df.replace(to_replace='FLO', value='MIA', inplace=True)\n",
        "\n",
        "# Updating game_df so team abbreviations match. Will be leveraged when aggregating teams stats\n",
        "parkfactor_df.replace(to_replace={\"NYA\":\"NYY\", \"SDN\":\"SD\", \"CHN\":\"CHC\", \"SLN\":\"STL\", \"SFN\":\"SF\", \"LAN\":\"LAD\", \"TBA\":\"TB\", \"KCA\":\"KC\", \"CHA\":\"CWS\", \"ANA\":\"LAA\", \"NYN\":\"NYM\"}, inplace=True)\n",
        "\n",
        "\n",
        "game_df = pd.merge(game_df, parkfactor_df, on=\"HomeTeam\")\n",
        "\n",
        "col_del = ['VisitorBatting1PlayerID', 'VisitorBatting1Name', 'VisitorBatting2PlayerID', 'VisitorBatting2Name', 'VisitorBatting3PlayerID', 'VisitorBatting3Name', 'VisitorBatting4PlayerID', 'VisitorBatting4Name', 'VisitorBatting5PlayerID', 'VisitorBatting5Name', 'VisitorBatting6PlayerID', 'VisitorBatting6Name', 'VisitorBatting7PlayerID', 'VisitorBatting7Name', 'VisitorBatting8PlayerID', 'VisitorBatting8Name', 'VisitorBatting9PlayerID', 'VisitorBatting9Name', 'HomeBatting1PlayerID', 'HomeBatting1Name', 'HomeBatting2PlayerID', 'HomeBatting2Name', 'HomeBatting3PlayerID', 'HomeBatting3Name', 'HomeBatting4PlayerID', 'HomeBatting4Name', 'HomeBatting5PlayerID', 'HomeBatting5Name', 'HomeBatting6PlayerID', 'HomeBatting6Name', 'HomeBatting7PlayerID', 'HomeBatting7Name', 'HomeBatting8PlayerID', 'HomeBatting8Name', 'HomeBatting9PlayerID', 'HomeBatting9Name']\n",
        "game_df.drop(col_del,axis=1,inplace=True)\n",
        "game_df = game_df.rename(columns={\"VisitingTeam\":\"VisitorTeam\",\"VisitingTeamGameNumber\":\"VisitorTeamGameNumber\"})\n",
        "\n",
        "game_df['Date'] = pd.to_datetime(game_df['Date'].astype(str), format='%Y%m%d')\n",
        "game_df['current_year'] = game_df['Date'].dt.year\n",
        "\n",
        "game_df['prior_year']=game_df['current_year']-1\n",
        "print(game_df.Attendence)\n",
        "trend=1 #몇일 롤링\n",
        "game_df[f'{trend}d_home_attendance'] = game_df.groupby(['current_year', 'HomeTeam'])['Attendence'].transform(lambda x: round(x.rolling(trend).mean().shift(periods=1, axis=0), 3))\n",
        "print(game_df[f'{trend}d_home_attendance'])\n",
        "\n",
        "away_inning = game_df['LengthInOuts']//2\n",
        "home_inning = game_df['LengthInOuts']- away_inning\n",
        "\n",
        "\n",
        "game_df['VisitorOffInn'] = away_inning\n",
        "game_df['VisitorDifInn'] = home_inning\n",
        "game_df['HomeOffInn'] = home_inning\n",
        "game_df['HomeDifInn'] = away_inning\n",
        "\n",
        "game_df['Home_team_won?'] = game_df['HomeRunsScore'] > game_df['VisitorRunsScored']\n",
        "game_df['Visitor_team_won?'] = game_df['HomeRunsScore'] < game_df['VisitorRunsScored']\n",
        "\n",
        "bat_stat = [ 'TeamGameNumber','Team','AB','H','D','T','HR','RBI','SH','SF',\n",
        "'HBP','BB','IBB','K','SB','CS','LOB','Pitchers',\n",
        "'ER','TER','WP','Balks','PO','A','E','Passed','DB','TP','OffInn','DifInn','_team_won?']\n",
        "pit_stat = ['H', 'D', 'T', 'HR', 'RBI', 'SH', 'SF', 'HBP', 'BB', 'IBB', 'K', 'LOB', 'ER','DB','AB']\n",
        "\n",
        "select_stat = ['Date']\n",
        "select_stat += ['Home'+i for i in bat_stat]+['Visitor'+i for i in pit_stat]\n",
        "rename1 = {'Visitor'+i:'Pit'+i for i in pit_stat}\n",
        "rename2 = {'Home'+i:i for i in bat_stat}\n",
        "\n",
        "## Home 시각 \n",
        "select_stat = ['Date']\n",
        "select_stat += ['Home'+i for i in bat_stat]+['Visitor'+i for i in pit_stat]\n",
        "rename1 = {'Visitor'+i:'Pit'+i for i in pit_stat}\n",
        "rename2 = {'Home'+i:i for i in bat_stat}\n",
        "Home = game_df.copy()\n",
        "Home = Home[select_stat].rename(columns=rename1)\n",
        "Home = Home.rename(columns=rename2)\n",
        "# away 시각\n",
        "select_stat = ['Date']\n",
        "select_stat += ['Visitor'+i for i in bat_stat]+['Home'+i for i in pit_stat]\n",
        "rename1 = {'Home'+i:'Pit'+i for i in pit_stat}\n",
        "rename2 = {'Visitor'+i:i for i in bat_stat}\n",
        "Visitor = game_df.copy()\n",
        "Visitor = Visitor[select_stat].rename(columns=rename1)\n",
        "Visitor = Visitor.rename(columns=rename2)\n",
        "\n",
        "sep_team = pd.concat([Home,Visitor])\n",
        "sep_team = sep_team.rename(columns={'PitDB':'DP'})\n",
        "sep_team\n",
        "\n",
        "col = ['AB', 'H', 'D', 'T', 'HR', 'RBI','DP',\n",
        "       'SF', 'BB', 'K', 'SB', 'CS', 'LOB', 'Pitchers', 'ER', 'TER', 'WP','PitAB',\n",
        "       'Balks', 'PO', 'A', 'E', 'Passed', 'DB', 'TP', 'OffInn', 'DifInn',\n",
        "       'PitH', 'PitD', 'PitT', 'PitHR', 'PitRBI', 'PitSF',\n",
        "       'PitBB', 'PitK', 'PitLOB', 'PitER']\n",
        "\n",
        "\n",
        "a = sep_team.copy()\n",
        "sep_team['year']= sep_team.Date.dt.year\n",
        "sep_team[col] = sep_team.groupby(['year','Team'])[col].transform(lambda x: x.expanding(1).sum())\n",
        "sep_team[col] = sep_team[col].subtract(a[col])\n",
        "sep_team = sep_team[sep_team['TeamGameNumber']>=10] #최소 10경기 이상\n",
        "sep_team\n",
        "\n",
        "select_feature = ['Date', 'TeamGameNumber', 'Team','_team_won?']\n",
        "# feature selection\n",
        "select_feature += ['AB', 'H', 'D', 'T', 'HR', 'RBI','BB', 'K','DP', 'HBP','IBB','SF','SH',#bat stat\n",
        "                    'ER','OffInn','DifInn' # game info\n",
        "                    ,'PitAB','PitH', 'PitD', 'PitT', 'PitHR', 'PitRBI', 'PitSF', 'PitBB',\"PitIBB\",\"PitHBP\" ,'PitK','PitLOB', 'PitER'\n",
        "                    ]\n",
        "sep = sep_team[select_feature] \n",
        "# H, OBP, SLG, ISO, Babip, RC, wOBA X, K, BB, RBI, K/B, HR   \n",
        "# 타자 가공\n",
        "sep['RC'] = ((sep['H']+sep['BB']+sep['HBP']-sep['DP'])\n",
        "        *(sep['H']+2*sep['D']+3*sep['T']+4*sep['HR']+0.52*(sep['SF']+sep['SH'])+0.26*(sep['BB']+sep['HBP']-sep['IBB']))\n",
        "        )/(sep['AB']*sep['AB']) #득점 생산\n",
        "\n",
        "\n",
        "#사구,사사구, 고의사구 통합\n",
        "sep['BB'] += sep['HBP']+sep['IBB']\n",
        "sep['PitBB'] += sep['PitHBP']+sep['PitIBB']\n",
        "#del sep['HBP'],sep['IBB'],sep['PitHBP'],sep['PitIBB']\n",
        "# 희생번트, 희생플라이 통합\n",
        "sep['PitSF'] += sep_team['PitSH']\n",
        "sep['SF'] += sep['SH']\n",
        "#del sep['SH'],sep['PitSH']\n",
        "\n",
        "sep['K/B'] = sep['K']/(sep['BB']+0.5)\n",
        "sep['PA'] = sep['AB'] - sep['BB'] - sep['SF'] # 타수\n",
        "sep['Babip'] = (sep['H']+sep['D']+sep['T']) / (sep['PA']-sep['K']-sep['HR']-sep['SF']) # 인플레이 타구\n",
        "sep['SLG'] = (sep['H']+2*sep['D']+3*sep['T']+4*sep['HR'])/sep['PA'] # 장타율\n",
        "sep['H'] = sep['H']/sep['PA'] # 안타율\n",
        "sep['D'] = sep['D']/sep['PA'] # 안타율\n",
        "sep['T'] = sep['T']/sep['PA'] # 안타율\n",
        "sep['HR'] = sep['HR']/sep['PA'] # 안타율\n",
        "sep['BB'] = sep['BB']/sep['PA'] # 볼넷\n",
        "sep['RBI'] = sep['RBI']/sep['TeamGameNumber'] # 득점\n",
        "\n",
        "sep['OBP'] = (sep['H']+sep['BB']) #출루율\n",
        "sep['OPS'] = sep['SLG']+sep['OBP'] #OPS\n",
        "sep['GPA'] = (1.8*sep['OBP']+sep['SLG'])/4#GPA(Gross Production Average) - park factor를 적용해야함\n",
        "sep['ISO'] = sep['SLG'] - sep['H']\n",
        "# 투수 가공\n",
        "# PitH, PitOBP, PitSLG, PitOPS, PitHR, EAR, PitB, PitK, PitK/B, WHIP, kwERA\n",
        "sep['ERA'] = sep['PitER']/sep['DifInn']\n",
        "sep['TotalH'] = sep['PitH']+sep['PitD']+sep['PitT']+sep['PitHR']\n",
        "sep['TotalBB'] = sep['PitBB']+sep['PitHBP']\n",
        "sep['PitPA'] = sep['PitAB'] - sep['TotalBB'] - sep['PitSF']\n",
        "sep['kwERA'] = (5.40-12*(sep['PitK'] - sep['TotalBB']))/sep['PitPA']\n",
        "sep['WHIP'] = (sep['TotalH']+sep['TotalBB'])/sep['DifInn']\n",
        "sep['PitK'] = sep['PitK']/sep['DifInn']\n",
        "sep['PitB'] = sep['TotalBB']/sep['DifInn']\n",
        "sep['PitK/B'] = sep['PitK']/(sep['PitB']+0.5)\n",
        "\n",
        "\n",
        "sep['PitSLG'] = (sep['PitH']+2*sep['PitD']+3*sep['PitT']+4*sep['PitHR'])/sep['PitPA'] # 피장타율\n",
        "sep['PitH'] = sep['PitH']/sep['PitPA'] # 피안타율\n",
        "sep['PitOBP'] = (sep['TotalH']+sep['TotalBB']) / sep['PitAB'] #피출루율\n",
        "sep['PitOPS'] = sep['PitSLG']+sep['PitOBP'] #피OPS\n",
        "sep['PitHR'] /= sep['PitPA']\n",
        "\n",
        "#ParkFactors\n",
        "\n",
        "temp = sep\n",
        "game_log = game_df[['Date','VisitorTeam','HomeTeam','VisitorTeamGameNumber','HomeTeamGameNumber',f'{trend}d_home_attendance','ParkFactors']]\n",
        "\n",
        "game_log = game_log[game_log.VisitorTeamGameNumber>=10]\n",
        "game_log = game_log[game_log.HomeTeamGameNumber>=10]\n",
        "\n",
        "\n",
        "\n",
        "game_log = pd.merge(game_log,temp,left_on = ['Date','VisitorTeam'], right_on = ['Date','Team'],how='left')\n",
        "game_log = pd.merge(game_log,temp,left_on = ['Date','HomeTeam'], right_on = ['Date','Team'],how='left')\n",
        "\n",
        "game_log['year'] = game_log.Date.dt.year\n",
        "\n",
        "\n",
        "\n",
        "y_cols = ['_team_won?_x']\n",
        "select = ['H','OBP','SLG','ISO','Babip','RC','K','BB','RBI','K/B','HR','PitH','PitOBP','PitSLG','PitOPS','PitHR','ERA','PitB','PitK','PitK/B','WHIP']\n",
        "#select = ['H', 'D', 'T', 'HR', 'RBI', 'BB']\n",
        "#x_cols = [i+'_x' for i in select]\n",
        "#x_cols += [i+'_y' for i in select]\n",
        "\n",
        "for i in select:\n",
        "  print(i)\n",
        "  \n",
        "  game_log[i]=game_log[i+'_x']/game_log[i+'_y']\n",
        "print(game_log.info())\n",
        "x_cols=select\n",
        "x_cols += [f'{trend}d_home_attendance']\n",
        "x_cols += ['ParkFactors']\n",
        "game_log=game_log.replace([np.inf, -np.inf], np.nan)\n",
        "game_log.dropna()\n",
        "train = game_log[game_log.year!=2019]\n",
        "test = game_log[game_log.year==2019]\n",
        "train = train.dropna()\n",
        "test = test.dropna()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "TMMHdToZ2HfE",
        "outputId": "7ae93f4b-d669-4a63-b48e-6207bdcf9e36"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e239a77e-2fe7-441a-8a47-37a647023900\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VisitorTeamGameNumber</th>\n",
              "      <th>HomeTeamGameNumber</th>\n",
              "      <th>1d_home_attendance</th>\n",
              "      <th>ParkFactors</th>\n",
              "      <th>TeamGameNumber_x</th>\n",
              "      <th>AB_x</th>\n",
              "      <th>H_x</th>\n",
              "      <th>D_x</th>\n",
              "      <th>T_x</th>\n",
              "      <th>HR_x</th>\n",
              "      <th>...</th>\n",
              "      <th>PitH</th>\n",
              "      <th>PitOBP</th>\n",
              "      <th>PitSLG</th>\n",
              "      <th>PitOPS</th>\n",
              "      <th>PitHR</th>\n",
              "      <th>ERA</th>\n",
              "      <th>PitB</th>\n",
              "      <th>PitK</th>\n",
              "      <th>PitK/B</th>\n",
              "      <th>WHIP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>24464.000000</td>\n",
              "      <td>24464.000000</td>\n",
              "      <td>24461.000000</td>\n",
              "      <td>24464.000000</td>\n",
              "      <td>24464.000000</td>\n",
              "      <td>24464.000000</td>\n",
              "      <td>24464.000000</td>\n",
              "      <td>24464.000000</td>\n",
              "      <td>24464.000000</td>\n",
              "      <td>24464.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>24462.000000</td>\n",
              "      <td>24463.000000</td>\n",
              "      <td>24462.000000</td>\n",
              "      <td>24463.000000</td>\n",
              "      <td>24430.000000</td>\n",
              "      <td>24461.000000</td>\n",
              "      <td>24463.000000</td>\n",
              "      <td>24462.000000</td>\n",
              "      <td>24462.000000</td>\n",
              "      <td>24463.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>86.454872</td>\n",
              "      <td>86.449804</td>\n",
              "      <td>0.682864</td>\n",
              "      <td>1.004674</td>\n",
              "      <td>86.454872</td>\n",
              "      <td>4100.900139</td>\n",
              "      <td>0.284216</td>\n",
              "      <td>0.056292</td>\n",
              "      <td>0.005962</td>\n",
              "      <td>0.035297</td>\n",
              "      <td>...</td>\n",
              "      <td>1.022928</td>\n",
              "      <td>1.018819</td>\n",
              "      <td>1.032877</td>\n",
              "      <td>1.025832</td>\n",
              "      <td>1.110184</td>\n",
              "      <td>1.037327</td>\n",
              "      <td>1.002816</td>\n",
              "      <td>0.987673</td>\n",
              "      <td>0.993916</td>\n",
              "      <td>1.003989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>44.299550</td>\n",
              "      <td>44.306926</td>\n",
              "      <td>0.239825</td>\n",
              "      <td>0.120131</td>\n",
              "      <td>44.299552</td>\n",
              "      <td>818.757280</td>\n",
              "      <td>0.015510</td>\n",
              "      <td>0.006265</td>\n",
              "      <td>0.002210</td>\n",
              "      <td>0.008998</td>\n",
              "      <td>...</td>\n",
              "      <td>0.110683</td>\n",
              "      <td>0.109176</td>\n",
              "      <td>0.153358</td>\n",
              "      <td>0.130782</td>\n",
              "      <td>0.434539</td>\n",
              "      <td>0.276134</td>\n",
              "      <td>0.207037</td>\n",
              "      <td>0.148753</td>\n",
              "      <td>0.161195</td>\n",
              "      <td>0.126097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.798000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1654.000000</td>\n",
              "      <td>0.238076</td>\n",
              "      <td>0.039328</td>\n",
              "      <td>0.000880</td>\n",
              "      <td>0.012302</td>\n",
              "      <td>...</td>\n",
              "      <td>0.514812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.266755</td>\n",
              "      <td>0.341784</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.557858</td>\n",
              "      <td>0.530280</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.508000</td>\n",
              "      <td>0.917000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>3392.000000</td>\n",
              "      <td>0.273670</td>\n",
              "      <td>0.051827</td>\n",
              "      <td>0.004374</td>\n",
              "      <td>0.028557</td>\n",
              "      <td>...</td>\n",
              "      <td>0.948135</td>\n",
              "      <td>0.945538</td>\n",
              "      <td>0.931638</td>\n",
              "      <td>0.938319</td>\n",
              "      <td>0.855622</td>\n",
              "      <td>0.862520</td>\n",
              "      <td>0.861638</td>\n",
              "      <td>0.882094</td>\n",
              "      <td>0.879471</td>\n",
              "      <td>0.918909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>87.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>0.702000</td>\n",
              "      <td>1.003000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>4106.000000</td>\n",
              "      <td>0.282857</td>\n",
              "      <td>0.055899</td>\n",
              "      <td>0.005810</td>\n",
              "      <td>0.034474</td>\n",
              "      <td>...</td>\n",
              "      <td>1.017804</td>\n",
              "      <td>1.013402</td>\n",
              "      <td>1.021353</td>\n",
              "      <td>1.017974</td>\n",
              "      <td>1.037421</td>\n",
              "      <td>1.000967</td>\n",
              "      <td>0.982300</td>\n",
              "      <td>0.974114</td>\n",
              "      <td>0.980006</td>\n",
              "      <td>0.996117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>0.881000</td>\n",
              "      <td>1.074000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>4803.000000</td>\n",
              "      <td>0.293738</td>\n",
              "      <td>0.059892</td>\n",
              "      <td>0.007221</td>\n",
              "      <td>0.041835</td>\n",
              "      <td>...</td>\n",
              "      <td>1.090584</td>\n",
              "      <td>1.086214</td>\n",
              "      <td>1.121269</td>\n",
              "      <td>1.104005</td>\n",
              "      <td>1.273894</td>\n",
              "      <td>1.167666</td>\n",
              "      <td>1.119727</td>\n",
              "      <td>1.077228</td>\n",
              "      <td>1.090661</td>\n",
              "      <td>1.079073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>163.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.394000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>5738.000000</td>\n",
              "      <td>0.351197</td>\n",
              "      <td>0.084293</td>\n",
              "      <td>0.016243</td>\n",
              "      <td>0.063880</td>\n",
              "      <td>...</td>\n",
              "      <td>2.103067</td>\n",
              "      <td>2.036987</td>\n",
              "      <td>2.605168</td>\n",
              "      <td>2.263405</td>\n",
              "      <td>11.542735</td>\n",
              "      <td>10.735495</td>\n",
              "      <td>3.228910</td>\n",
              "      <td>1.941696</td>\n",
              "      <td>2.340909</td>\n",
              "      <td>2.142820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 126 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e239a77e-2fe7-441a-8a47-37a647023900')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e239a77e-2fe7-441a-8a47-37a647023900 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e239a77e-2fe7-441a-8a47-37a647023900');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       VisitorTeamGameNumber  HomeTeamGameNumber  1d_home_attendance  \\\n",
              "count           24464.000000        24464.000000        24461.000000   \n",
              "mean               86.454872           86.449804            0.682864   \n",
              "std                44.299550           44.306926            0.239825   \n",
              "min                10.000000           10.000000            0.000000   \n",
              "25%                48.000000           48.000000            0.508000   \n",
              "50%                87.000000           87.000000            0.702000   \n",
              "75%               125.000000          125.000000            0.881000   \n",
              "max               163.000000          163.000000            1.580000   \n",
              "\n",
              "        ParkFactors  TeamGameNumber_x          AB_x           H_x  \\\n",
              "count  24464.000000      24464.000000  24464.000000  24464.000000   \n",
              "mean       1.004674         86.454872   4100.900139      0.284216   \n",
              "std        0.120131         44.299552    818.757280      0.015510   \n",
              "min        0.798000         10.000000   1654.000000      0.238076   \n",
              "25%        0.917000         48.000000   3392.000000      0.273670   \n",
              "50%        1.003000         87.000000   4106.000000      0.282857   \n",
              "75%        1.074000        125.000000   4803.000000      0.293738   \n",
              "max        1.394000        163.000000   5738.000000      0.351197   \n",
              "\n",
              "                D_x           T_x          HR_x  ...          PitH  \\\n",
              "count  24464.000000  24464.000000  24464.000000  ...  24462.000000   \n",
              "mean       0.056292      0.005962      0.035297  ...      1.022928   \n",
              "std        0.006265      0.002210      0.008998  ...      0.110683   \n",
              "min        0.039328      0.000880      0.012302  ...      0.514812   \n",
              "25%        0.051827      0.004374      0.028557  ...      0.948135   \n",
              "50%        0.055899      0.005810      0.034474  ...      1.017804   \n",
              "75%        0.059892      0.007221      0.041835  ...      1.090584   \n",
              "max        0.084293      0.016243      0.063880  ...      2.103067   \n",
              "\n",
              "             PitOBP        PitSLG        PitOPS         PitHR           ERA  \\\n",
              "count  24463.000000  24462.000000  24463.000000  24430.000000  24461.000000   \n",
              "mean       1.018819      1.032877      1.025832      1.110184      1.037327   \n",
              "std        0.109176      0.153358      0.130782      0.434539      0.276134   \n",
              "min        0.000000      0.471481      0.000000      0.266755      0.341784   \n",
              "25%        0.945538      0.931638      0.938319      0.855622      0.862520   \n",
              "50%        1.013402      1.021353      1.017974      1.037421      1.000967   \n",
              "75%        1.086214      1.121269      1.104005      1.273894      1.167666   \n",
              "max        2.036987      2.605168      2.263405     11.542735     10.735495   \n",
              "\n",
              "               PitB          PitK        PitK/B          WHIP  \n",
              "count  24463.000000  24462.000000  24462.000000  24463.000000  \n",
              "mean       1.002816      0.987673      0.993916      1.003989  \n",
              "std        0.207037      0.148753      0.161195      0.126097  \n",
              "min        0.000000      0.557858      0.530280      0.000000  \n",
              "25%        0.861638      0.882094      0.879471      0.918909  \n",
              "50%        0.982300      0.974114      0.980006      0.996117  \n",
              "75%        1.119727      1.077228      1.090661      1.079073  \n",
              "max        3.228910      1.941696      2.340909      2.142820  \n",
              "\n",
              "[8 rows x 126 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "game_log.describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "aAhT4DEDf7Ye",
        "outputId": "c512e57f-d6dd-44d4-b3c7-ef72ceb3bfbf"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-43158ab9e17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_call\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m         )\n\u001b[1;32m    849\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
          ]
        }
      ],
      "source": [
        "'''\n",
        "    Z-score normalization\n",
        "'''\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train[x_cols])\n",
        "X_train = scaler.transform(train[x_cols])\n",
        "X_test = scaler.transform(test[x_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMZD0t92gJCk",
        "outputId": "21d78290-78f6-43c2-8a26-2e7bbc990f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.681472\n",
            "         Iterations 5\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:           _team_won?_x   No. Observations:                21929\n",
            "Model:                          Logit   Df Residuals:                    21906\n",
            "Method:                           MLE   Df Model:                           22\n",
            "Date:                Fri, 06 May 2022   Pseudo R-squ.:                 0.01302\n",
            "Time:                        11:57:58   Log-Likelihood:                -14944.\n",
            "converged:                       True   LL-Null:                       -15141.\n",
            "Covariance Type:            nonrobust   LLR p-value:                 6.486e-70\n",
            "======================================================================================\n",
            "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "H                     -0.3499      0.927     -0.377      0.706      -2.167       1.467\n",
            "OBP                    1.6591      1.084      1.530      0.126      -0.466       3.785\n",
            "SLG                    2.2295      1.082      2.061      0.039       0.109       4.350\n",
            "ISO                    0.0583      0.487      0.120      0.905      -0.896       1.013\n",
            "Babip                  0.4659      0.456      1.022      0.307      -0.428       1.360\n",
            "RC                    -2.2924      0.428     -5.353      0.000      -3.132      -1.453\n",
            "K                      0.0150      0.005      2.965      0.003       0.005       0.025\n",
            "BB                    -0.3547      0.269     -1.317      0.188      -0.882       0.173\n",
            "RBI                   -0.0071      0.005     -1.489      0.136      -0.016       0.002\n",
            "K/B                   -0.4989      0.129     -3.862      0.000      -0.752      -0.246\n",
            "HR                     0.0717      0.054      1.332      0.183      -0.034       0.177\n",
            "PitH                  -1.6414      0.642     -2.558      0.011      -2.899      -0.384\n",
            "PitOBP                 6.6403      5.213      1.274      0.203      -3.576      16.857\n",
            "PitSLG                 4.9083      5.814      0.844      0.399      -6.487      16.304\n",
            "PitOPS               -10.6695     10.610     -1.006      0.315     -31.464      10.125\n",
            "PitHR                 -0.0779      0.065     -1.195      0.232      -0.206       0.050\n",
            "ERA                    0.3043      0.153      1.989      0.047       0.005       0.604\n",
            "PitB                  -0.9256      0.263     -3.519      0.000      -1.441      -0.410\n",
            "PitK                   2.1486      1.160      1.852      0.064      -0.125       4.423\n",
            "PitK/B                -1.6605      1.136     -1.462      0.144      -3.887       0.566\n",
            "WHIP                   0.1782      0.844      0.211      0.833      -1.476       1.833\n",
            "1d_home_attendance    -0.0454      0.060     -0.758      0.449      -0.163       0.072\n",
            "ParkFactors           -0.2445      0.122     -1.999      0.046      -0.484      -0.005\n",
            "======================================================================================\n",
            "Train accuracy =  0.5626339550367094\n",
            "Test accuracy =  0.5866935483870968\n"
          ]
        }
      ],
      "source": [
        "X_train = train[x_cols]\n",
        "y_train = train[y_cols]*1\n",
        "\n",
        "X_test = test[x_cols]\n",
        "y_test = test[y_cols]*1\n",
        "\n",
        "model = sm.Logit(y_train,X_train)\n",
        "results = model.fit()\n",
        "print(results.summary())\n",
        "\n",
        "y_hat = results.predict( X_train)\n",
        "y_hat = list(map(round,y_hat))\n",
        "print('Train accuracy = ', accuracy_score(y_train, y_hat))\n",
        "\n",
        "y_hat = results.predict( X_test)\n",
        "y_hat = list(map(round,y_hat))\n",
        "print('Test accuracy = ', accuracy_score(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7j-l1WFXkz6n",
        "outputId": "b5d3378e-8a5d-4a0a-e1e2-524c7cf520d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.689655\n",
            "[2]\tvalid_0's binary_logloss: 0.688711\n",
            "[3]\tvalid_0's binary_logloss: 0.68761\n",
            "[4]\tvalid_0's binary_logloss: 0.686368\n",
            "[5]\tvalid_0's binary_logloss: 0.685587\n",
            "[6]\tvalid_0's binary_logloss: 0.684723\n",
            "[7]\tvalid_0's binary_logloss: 0.684231\n",
            "[8]\tvalid_0's binary_logloss: 0.684032\n",
            "[9]\tvalid_0's binary_logloss: 0.682867\n",
            "[10]\tvalid_0's binary_logloss: 0.681975\n",
            "[11]\tvalid_0's binary_logloss: 0.681336\n",
            "[12]\tvalid_0's binary_logloss: 0.680472\n",
            "[13]\tvalid_0's binary_logloss: 0.679823\n",
            "[14]\tvalid_0's binary_logloss: 0.679087\n",
            "[15]\tvalid_0's binary_logloss: 0.678627\n",
            "[16]\tvalid_0's binary_logloss: 0.678342\n",
            "[17]\tvalid_0's binary_logloss: 0.677898\n",
            "[18]\tvalid_0's binary_logloss: 0.677316\n",
            "[19]\tvalid_0's binary_logloss: 0.676848\n",
            "[20]\tvalid_0's binary_logloss: 0.67665\n",
            "[21]\tvalid_0's binary_logloss: 0.676365\n",
            "[22]\tvalid_0's binary_logloss: 0.675905\n",
            "[23]\tvalid_0's binary_logloss: 0.675556\n",
            "[24]\tvalid_0's binary_logloss: 0.674956\n",
            "[25]\tvalid_0's binary_logloss: 0.674799\n",
            "[26]\tvalid_0's binary_logloss: 0.674808\n",
            "[27]\tvalid_0's binary_logloss: 0.67475\n",
            "[28]\tvalid_0's binary_logloss: 0.674576\n",
            "[29]\tvalid_0's binary_logloss: 0.674411\n",
            "[30]\tvalid_0's binary_logloss: 0.674135\n",
            "[31]\tvalid_0's binary_logloss: 0.67451\n",
            "[32]\tvalid_0's binary_logloss: 0.674305\n",
            "[33]\tvalid_0's binary_logloss: 0.674261\n",
            "[34]\tvalid_0's binary_logloss: 0.674224\n",
            "[35]\tvalid_0's binary_logloss: 0.674121\n",
            "[36]\tvalid_0's binary_logloss: 0.6738\n",
            "[37]\tvalid_0's binary_logloss: 0.674239\n",
            "[38]\tvalid_0's binary_logloss: 0.674234\n",
            "[39]\tvalid_0's binary_logloss: 0.674054\n",
            "[40]\tvalid_0's binary_logloss: 0.67405\n",
            "[41]\tvalid_0's binary_logloss: 0.673828\n",
            "[42]\tvalid_0's binary_logloss: 0.673825\n",
            "[43]\tvalid_0's binary_logloss: 0.6738\n",
            "[44]\tvalid_0's binary_logloss: 0.674338\n",
            "[45]\tvalid_0's binary_logloss: 0.674065\n",
            "[46]\tvalid_0's binary_logloss: 0.673691\n",
            "[47]\tvalid_0's binary_logloss: 0.673631\n",
            "[48]\tvalid_0's binary_logloss: 0.673632\n",
            "[49]\tvalid_0's binary_logloss: 0.673572\n",
            "[50]\tvalid_0's binary_logloss: 0.673706\n",
            "[51]\tvalid_0's binary_logloss: 0.673563\n",
            "[52]\tvalid_0's binary_logloss: 0.673574\n",
            "[53]\tvalid_0's binary_logloss: 0.673156\n",
            "[54]\tvalid_0's binary_logloss: 0.673136\n",
            "[55]\tvalid_0's binary_logloss: 0.673101\n",
            "[56]\tvalid_0's binary_logloss: 0.673097\n",
            "[57]\tvalid_0's binary_logloss: 0.672892\n",
            "[58]\tvalid_0's binary_logloss: 0.673716\n",
            "[59]\tvalid_0's binary_logloss: 0.673735\n",
            "[60]\tvalid_0's binary_logloss: 0.673545\n",
            "[61]\tvalid_0's binary_logloss: 0.673498\n",
            "[62]\tvalid_0's binary_logloss: 0.673482\n",
            "[63]\tvalid_0's binary_logloss: 0.673291\n",
            "[64]\tvalid_0's binary_logloss: 0.673213\n",
            "[65]\tvalid_0's binary_logloss: 0.673244\n",
            "[66]\tvalid_0's binary_logloss: 0.673296\n",
            "[67]\tvalid_0's binary_logloss: 0.673227\n",
            "{'max_depth': -1, 'num_leaves': 4}\n",
            "0.5783326621022956\n",
            "{'max_depth': 3, 'min_samples_split': 6}\n",
            "0.5730970600080548\n"
          ]
        }
      ],
      "source": [
        "num_thread = 8\n",
        "# num of cpu \n",
        "param ={'num_leaves':[4,6,8,10,20],'max_depth':[-1,3,6,9,12,15]}\n",
        "lgb =LGBMClassifier()\n",
        "lgb_clf = GridSearchCV(lgb,param,scoring='accuracy',n_jobs=num_thread)\n",
        "lgb_results = lgb_clf.fit(X_train, y_train.values.ravel(), eval_metric=['logloss'],eval_set=[(X_test, y_test.values.ravel())],callbacks=[lightgbm.early_stopping(10, verbose=0)])\n",
        "\n",
        "train_score = lgb_results.score(X_train, y_train)\n",
        "test_score = lgb_results.score(X_test, y_test)\n",
        "print(lgb_results.best_params_)\n",
        "print(test_score)\n",
        "\n",
        "rf_param ={'min_samples_split':[4,6,8,10,20],'max_depth':[-1,3,6,9,12,15]}\n",
        "rf =RandomForestClassifier()\n",
        "rf_clf = GridSearchCV(rf,rf_param,scoring='accuracy',n_jobs=num_thread)\n",
        "rf_results = rf_clf.fit(X_train,  y_train.values.ravel())\n",
        "\n",
        "\n",
        "train_score = rf_results.score(X_train, y_train)\n",
        "test_score = rf_results.score(X_test, y_test)\n",
        "print(rf_results.best_params_)\n",
        "print(test_score)\n",
        "\n",
        "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0] \n",
        "svm_param  = [{'C': param_range, 'kernel': ['linear']}, {'C': param_range, 'gamma': param_range, 'kernel': ['rbf']}]\n",
        "svm_model =svm.SVC()\n",
        "svm_clf = GridSearchCV(estimator=svm_model,param_grid=svm_param,scoring='accuracy',n_jobs=num_thread,verbose=0)\n",
        "svm_results = svm_clf.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "train_score = svm_results.score(X_train, y_train)\n",
        "test_score = svm_results.score(X_test, y_test)\n",
        "print(svm_results.best_params_)\n",
        "print(test_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuOjkFxllAzB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNQexFZOlWWZ",
        "outputId": "302f4847-ac10-44bc-f553-2dca3246fbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rtdl\n",
            "  Downloading rtdl-0.0.13-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: torch<2,>=1.7 in /usr/local/lib/python3.7/dist-packages (from rtdl) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy<2,>=1.18 in /usr/local/lib/python3.7/dist-packages (from rtdl) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.7->rtdl) (4.2.0)\n",
            "Installing collected packages: rtdl\n",
            "Successfully installed rtdl-0.0.13\n",
            "Collecting libzero==0.0.4\n",
            "  Downloading libzero-0.0.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.17 in /usr/local/lib/python3.7/dist-packages (from libzero==0.0.4) (1.21.6)\n",
            "Requirement already satisfied: torch<2,>=1.6 in /usr/local/lib/python3.7/dist-packages (from libzero==0.0.4) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm<5,>=4.0 in /usr/local/lib/python3.7/dist-packages (from libzero==0.0.4) (4.64.0)\n",
            "Collecting pynvml<9,>=8.0\n",
            "  Downloading pynvml-8.0.4-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.6->libzero==0.0.4) (4.2.0)\n",
            "Installing collected packages: pynvml, libzero\n",
            "Successfully installed libzero-0.0.4 pynvml-8.0.4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123456"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Requirements:\n",
        "!pip install rtdl\n",
        "!pip install libzero==0.0.4\n",
        "\n",
        "from typing import Any, Dict\n",
        "\n",
        "import numpy as np\n",
        "import rtdl\n",
        "import scipy.special\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import zero\n",
        "\n",
        "#device = torch.device('cpu')\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "# Docs: https://yura52.github.io/zero/0.0.4/reference/api/zero.improve_reproducibility.html\n",
        "zero.improve_reproducibility(seed=123456)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x-NUk2hlfSE"
      },
      "outputs": [],
      "source": [
        "# # !!! NOTE !!! The dataset splits, preprocessing and other details are\n",
        "# # significantly different from those used in the\n",
        "# # paper \"Revisiting Deep Learning Models for Tabular Data\",\n",
        "# # so the results will be different from the reported in the paper.\n",
        "\n",
        "# dataset = sklearn.datasets.fetch_california_housing()\n",
        "# task_type = 'regression'\n",
        "\n",
        "# # dataset = sklearn.datasets.fetch_covtype()\n",
        "# # task_type = 'multiclass'\n",
        "\n",
        "# assert task_type in ['binclass', 'multiclass', 'regression']\n",
        "\n",
        "# X_all = dataset['data'].astype('float32')\n",
        "# y_all = dataset['target'].astype('float32' if task_type == 'regression' else 'int64')\n",
        "# if task_type != 'regression':\n",
        "#     y_all = sklearn.preprocessing.LabelEncoder().fit_transform(y_all).astype('int64')\n",
        "# n_classes = int(max(y_all)) + 1 if task_type == 'multiclass' else None\n",
        "\n",
        "# X = {}\n",
        "# y = {}\n",
        "# X['train'], X['test'], y['train'], y['test'] = sklearn.model_selection.train_test_split(\n",
        "#     X_all, y_all, train_size=0.8\n",
        "# )\n",
        "# X['train'], X['val'], y['train'], y['val'] = sklearn.model_selection.train_test_split(\n",
        "#     X['train'], y['train'], train_size=0.8\n",
        "# )\n",
        "\n",
        "# # not the best way to preprocess features, but enough for the demonstration\n",
        "# preprocess = sklearn.preprocessing.StandardScaler().fit(X['train'])\n",
        "# X = {\n",
        "#     k: torch.tensor(preprocess.fit_transform(v), device=device)\n",
        "#     for k, v in X.items()\n",
        "# }\n",
        "# y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n",
        "\n",
        "# # !!! CRUCIAL for neural networks when solving regression problems !!!\n",
        "# if task_type == 'regression':\n",
        "#     y_mean = y['train'].mean().item()\n",
        "#     y_std = y['train'].std().item()\n",
        "#     y = {k: (v - y_mean) / y_std for k, v in y.items()}\n",
        "# else:\n",
        "#     y_std = y_mean = None\n",
        "\n",
        "# if task_type != 'multiclass':\n",
        "#     y = {k: v.float() for k, v in y.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y848DYodokXv",
        "outputId": "d322cf69-8e06-46f0-e30b-79c26767cbd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       _team_won?_x\n",
            "0                 1\n",
            "1                 1\n",
            "2                 1\n",
            "3                 1\n",
            "4                 0\n",
            "...             ...\n",
            "24385             0\n",
            "24386             1\n",
            "24387             0\n",
            "24388             0\n",
            "24389             0\n",
            "\n",
            "[21929 rows x 1 columns]\n",
            "[1 1 1 ... 0 0 0]\n",
            "              H       OBP       SLG       ISO     Babip        RC          K  \\\n",
            "0      0.943219  1.116067  0.948231  0.953428  0.981830  1.044089  34.055556   \n",
            "1      1.064780  1.172302  1.037013  1.010039  1.100000  1.206117  24.000000   \n",
            "2      1.022395  1.168678  0.931633  0.854571  1.050847  1.042585  18.676471   \n",
            "3      1.047315  1.194011  0.975034  0.911630  1.060606  1.164231  16.435897   \n",
            "4      1.254523  1.194784  1.085205  0.937387  1.107602  1.392407  10.534884   \n",
            "...         ...       ...       ...       ...       ...       ...        ...   \n",
            "24385  1.055954  0.985154  1.005238  0.962307  1.006109  1.018790   2.019090   \n",
            "24386  0.963683  0.905980  0.862859  0.778234  0.934953  0.809477   2.172012   \n",
            "24387  0.962831  0.905332  0.864636  0.781910  0.934315  0.810598   2.153736   \n",
            "24388  0.961255  0.904913  0.858034  0.771925  0.929834  0.803647   2.138810   \n",
            "24389  1.043341  0.977070  0.984771  0.935836  0.993932  0.988758   1.940028   \n",
            "\n",
            "             BB        RBI       K/B  ...    PitSLG    PitOPS     PitHR  \\\n",
            "0      1.721039  25.923077  0.875861  ...  0.818612  0.808309  0.737860   \n",
            "1      1.453514  24.285714  0.971514  ...  0.975626  0.954502  0.840405   \n",
            "2      1.607529  18.157895  0.857734  ...  0.989182  0.973219  0.878311   \n",
            "3      1.625470  17.600000  0.837346  ...  0.936968  0.928338  0.761796   \n",
            "4      1.045436  19.776224  0.889437  ...  0.851746  0.866811  0.742958   \n",
            "...         ...        ...       ...  ...       ...       ...       ...   \n",
            "24385  0.829289   2.408022  1.096765  ...  1.113707  1.120236  1.016212   \n",
            "24386  0.779283   1.822785  1.284623  ...  1.111688  1.122834  1.005928   \n",
            "24387  0.779489   1.821317  1.283125  ...  1.108799  1.120174  0.994976   \n",
            "24388  0.780243   1.788344  1.281472  ...  1.116195  1.126829  1.008656   \n",
            "24389  0.829288   2.194118  1.105566  ...  1.133918  1.138806  1.040637   \n",
            "\n",
            "            ERA      PitB      PitK    PitK/B      WHIP  1d_home_attendance  \\\n",
            "0      1.072209  0.561710  1.502693  1.713504  0.800867               1.013   \n",
            "1      1.408993  0.683701  1.276285  1.382828  0.968160               0.982   \n",
            "2      1.238752  0.691241  1.114530  1.204065  0.992963               0.981   \n",
            "3      1.403666  0.647749  1.136711  1.247527  0.960536               0.984   \n",
            "4      1.718138  0.705758  1.117734  1.210413  0.940832               0.996   \n",
            "...         ...       ...       ...       ...       ...                 ...   \n",
            "24385  1.098550  1.340480  0.898379  0.853822  1.095996               0.885   \n",
            "24386  0.841902  1.317719  0.866645  0.826794  1.103814               0.895   \n",
            "24387  0.845678  1.300096  0.868539  0.830136  1.101584               0.937   \n",
            "24388  0.835479  1.321620  0.867539  0.827292  1.106599               0.956   \n",
            "24389  1.049204  1.365365  0.882453  0.836282  1.110247               0.897   \n",
            "\n",
            "       ParkFactors  \n",
            "0            1.063  \n",
            "1            1.063  \n",
            "2            1.063  \n",
            "3            1.063  \n",
            "4            1.063  \n",
            "...            ...  \n",
            "24385        0.905  \n",
            "24386        0.905  \n",
            "24387        0.905  \n",
            "24388        0.905  \n",
            "24389        0.905  \n",
            "\n",
            "[21929 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "X_train.shape\n",
        "\n",
        "X = {}\n",
        "y = {}\n",
        "\n",
        "# X_train = train[x_cols]\n",
        "# y_train = train[y_cols]*1\n",
        "\n",
        "# X_test = test[x_cols]\n",
        "# y_test = test[y_cols]*1\n",
        "print(y_train)\n",
        "y_train = sklearn.preprocessing.LabelEncoder().fit_transform(y_train).astype('int64')\n",
        "y_test = sklearn.preprocessing.LabelEncoder().fit_transform(y_test).astype('int64')\n",
        "\n",
        "print(y_train)\n",
        "\n",
        "X['train']=X_train\n",
        "X['test']=X_test\n",
        "y['train']=y_train\n",
        "y['test']=y_test\n",
        "\n",
        "\n",
        "# not the best way to preprocess features, but enough for the demonstration\n",
        "preprocess = sklearn.preprocessing.StandardScaler().fit(X['train'])\n",
        "X = {\n",
        "    k: torch.tensor(preprocess.fit_transform(v), device=device)\n",
        "    for k, v in X.items()\n",
        "}\n",
        "y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n",
        "\n",
        "print(X_train)\n",
        "X['train']=torch.tensor(X['train'],dtype=torch.float32)\n",
        "X['test']=torch.tensor(X['test'],dtype=torch.float32)\n",
        "X['train']\n",
        "\n",
        "X['train'], X['val'], y['train'], y['val'] = sklearn.model_selection.train_test_split(\n",
        "    X['train'], y['train'], train_size=0.8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "buQuJFLEmcbw"
      },
      "outputs": [],
      "source": [
        "task_type ='binclass'\n",
        "d_out = 1\n",
        "\n",
        "model = rtdl.MLP.make_baseline(\n",
        "    d_in=X_train.shape[1],\n",
        "    d_layers=[128, 256, 128],\n",
        "    dropout=0.1,\n",
        "    d_out=d_out,\n",
        ")\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "# model = rtdl.ResNet.make_baseline(\n",
        "#     d_in=X_all.shape[1],\n",
        "#     d_main=128,\n",
        "#     d_intermidiate=256,\n",
        "#     dropout_first=0.2,\n",
        "#     dropout_second=0.0,\n",
        "#     n_blocks=2,\n",
        "#     d_out=d_out,\n",
        "# )\n",
        "# lr = 0.001\n",
        "# weight_decay = 0.0\n",
        "\n",
        "# model = rtdl.FTTransformer.make_default(\n",
        "#     n_num_features=X_all.shape[1],\n",
        "#     cat_cardinalities=None,\n",
        "#     last_layer_query_idx=[-1],  # it makes the model faster and does NOT affect its output\n",
        "#     d_out=d_out,\n",
        "# )\n",
        "\n",
        "# === ABOUT CATEGORICAL FEATURES ===\n",
        "# IF you use MLP, ResNet or any other simple feed-forward model (NOT transformer-based model)\n",
        "# AND there are categorical features\n",
        "# THEN you have to implement a wrapper that handles categorical features.\n",
        "# The example below demonstrates how it can be achieved using rtdl.CategoricalFeatureTokenizer.\n",
        "# ==================================\n",
        "# 1. When you have both numerical and categorical features, you should prepare you data like this:\n",
        "#    (X_num<float32>, X_cat<int64>) instead of X<float32>\n",
        "#    Each column in X_cat should contain values within the range from 0 to <(the number of unique values in column) - 1>;\n",
        "#    use sklean.preprocessing.OrdinalEncoder to achieve this;\n",
        "# 2. Prepare a list of so called \"cardinalities\":\n",
        "#    cardinalities[i] = <the number of unique values of the i-th categorical feature>\n",
        "# 3. See the commented example below and adapt it for your needs.\n",
        "#\n",
        "# class Model(nn.Module):\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         n_num_features: int,\n",
        "#         cat_tokenizer: rtdl.CategoricalFeatureTokenizer,\n",
        "#         mlp_kwargs: Dict[str, Any],\n",
        "#     ):\n",
        "#         super().__init__()\n",
        "#         self.cat_tokenizer = cat_tokenizer\n",
        "#         self.model = rtdl.MLP.make_baseline(\n",
        "#             d_in=n_num_features + cat_tokenizer.n_tokens * cat_tokenizer.d_token,\n",
        "#             **mlp_kwargs,\n",
        "#         )\n",
        "#\n",
        "#     def forward(self, x_num, x_cat):\n",
        "#         return self.model(\n",
        "#             torch.cat([x_num, self.cat_tokenizer(x_cat).flatten(1, -1)], dim=1)\n",
        "#         )\n",
        "#\n",
        "# model = Model(\n",
        "#     # `None` means \"Do not transform numerical features\"\n",
        "#     # `d_token` is the size of embedding for ONE categorical feature\n",
        "#     X_num_all.shape[1],\n",
        "#     rtdl.CategoricalFeatureTokenizer(cardinalities, d_token, True, 'uniform'),\n",
        "#     mlp_kwargs,\n",
        "# )\n",
        "# Then the model should be used as `model(x_num, x_cat)` instead of of `model(x)`.\n",
        "\n",
        "model.to(device)\n",
        "# optimizer = (\n",
        "#     model.make_default_optimizer()\n",
        "#     if isinstance(model, rtdl.FTTransformer)\n",
        "#     else torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "# )\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
        "loss_fn = (\n",
        "    F.binary_cross_entropy_with_logits\n",
        "    if task_type == 'binclass'\n",
        "    else F.cross_entropy\n",
        "    if task_type == 'multiclass'\n",
        "    else F.mse_loss\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJPS9UyLmgcZ",
        "outputId": "81d8eb18-88d5-413c-a65a-e577a31fcb7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score before training: 0.5319\n"
          ]
        }
      ],
      "source": [
        "def apply_model(x_num, x_cat=None):\n",
        "    if isinstance(model, rtdl.FTTransformer):\n",
        "        return model(x_num, x_cat)\n",
        "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
        "        assert x_cat is None\n",
        "        return model(x_num)\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            f'Looks like you are using a custom model: {type(model)}.'\n",
        "            ' Then you have to implement this branch first.'\n",
        "        )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(part):\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    for batch in zero.iter_batches(X[part], 1024):\n",
        "        prediction.append(apply_model(batch))\n",
        "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
        "    target = y[part].cpu().numpy()\n",
        "\n",
        "    if task_type == 'binclass':\n",
        "        prediction = np.round(scipy.special.expit(prediction))\n",
        "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
        "    elif task_type == 'multiclass':\n",
        "        prediction = prediction.argmax(1)\n",
        "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
        "    else:\n",
        "        assert task_type == 'regression'\n",
        "        score = sklearn.metrics.mean_squared_error(target, prediction) ** 0.5 * y_std\n",
        "    return score\n",
        "\n",
        "\n",
        "# Create a dataloader for batches of indices\n",
        "# Docs: https://yura52.github.io/zero/reference/api/zero.data.IndexLoader.html\n",
        "batch_size = 256\n",
        "train_loader = zero.data.IndexLoader(len(X['train']), batch_size, device=device)\n",
        "\n",
        "# Create a progress tracker for early stopping\n",
        "# Docs: https://yura52.github.io/zero/reference/api/zero.ProgressTracker.html\n",
        "progress = zero.ProgressTracker(patience=100)\n",
        "\n",
        "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCpGiSn8miK9",
        "outputId": "3b230b3c-1092-4166-8d83-6f1a32727e03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | loss: 0.6920 | Validation score: 0.5271 | Test score: 0.5319\n",
            "Epoch 002 | loss: 0.6919 | Validation score: 0.5276 | Test score: 0.5327\n",
            "Epoch 003 | loss: 0.6918 | Validation score: 0.5280 | Test score: 0.5327\n",
            "Epoch 004 | loss: 0.6915 | Validation score: 0.5278 | Test score: 0.5327\n",
            "Epoch 005 | loss: 0.6917 | Validation score: 0.5276 | Test score: 0.5327\n",
            "Epoch 006 | loss: 0.6916 | Validation score: 0.5278 | Test score: 0.5331\n",
            "Epoch 007 | loss: 0.6914 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 008 | loss: 0.6912 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 009 | loss: 0.6912 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 010 | loss: 0.6910 | Validation score: 0.5276 | Test score: 0.5331\n",
            "Epoch 011 | loss: 0.6909 | Validation score: 0.5276 | Test score: 0.5331\n",
            "Epoch 012 | loss: 0.6909 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 013 | loss: 0.6908 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 014 | loss: 0.6906 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 015 | loss: 0.6904 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 016 | loss: 0.6905 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 017 | loss: 0.6905 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 018 | loss: 0.6904 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 019 | loss: 0.6900 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 020 | loss: 0.6900 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 021 | loss: 0.6900 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 022 | loss: 0.6899 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 023 | loss: 0.6900 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 024 | loss: 0.6899 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 025 | loss: 0.6898 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 026 | loss: 0.6897 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 027 | loss: 0.6896 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 028 | loss: 0.6895 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 029 | loss: 0.6895 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 030 | loss: 0.6894 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 031 | loss: 0.6893 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 032 | loss: 0.6894 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 033 | loss: 0.6895 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 034 | loss: 0.6894 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 035 | loss: 0.6893 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 036 | loss: 0.6889 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 037 | loss: 0.6890 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 038 | loss: 0.6890 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 039 | loss: 0.6890 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 040 | loss: 0.6891 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 041 | loss: 0.6889 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 042 | loss: 0.6887 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 043 | loss: 0.6888 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 044 | loss: 0.6887 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 045 | loss: 0.6886 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 046 | loss: 0.6883 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 047 | loss: 0.6886 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 048 | loss: 0.6885 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 049 | loss: 0.6884 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 050 | loss: 0.6883 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 051 | loss: 0.6885 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 052 | loss: 0.6884 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 053 | loss: 0.6883 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 054 | loss: 0.6883 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 055 | loss: 0.6882 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 056 | loss: 0.6882 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 057 | loss: 0.6881 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 058 | loss: 0.6881 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 059 | loss: 0.6881 | Validation score: 0.5274 | Test score: 0.5327\n",
            "Epoch 060 | loss: 0.6879 | Validation score: 0.5274 | Test score: 0.5327\n",
            "Epoch 061 | loss: 0.6879 | Validation score: 0.5274 | Test score: 0.5327\n",
            "Epoch 062 | loss: 0.6878 | Validation score: 0.5274 | Test score: 0.5327\n",
            "Epoch 063 | loss: 0.6878 | Validation score: 0.5274 | Test score: 0.5327\n",
            "Epoch 064 | loss: 0.6879 | Validation score: 0.5274 | Test score: 0.5327\n",
            "Epoch 065 | loss: 0.6878 | Validation score: 0.5274 | Test score: 0.5327\n",
            "Epoch 066 | loss: 0.6875 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 067 | loss: 0.6876 | Validation score: 0.5274 | Test score: 0.5331\n",
            "Epoch 068 | loss: 0.6876 | Validation score: 0.5274 | Test score: 0.5335\n",
            "Epoch 069 | loss: 0.6874 | Validation score: 0.5274 | Test score: 0.5335\n",
            "Epoch 070 | loss: 0.6875 | Validation score: 0.5274 | Test score: 0.5335\n",
            "Epoch 071 | loss: 0.6874 | Validation score: 0.5274 | Test score: 0.5335\n",
            "Epoch 072 | loss: 0.6874 | Validation score: 0.5274 | Test score: 0.5335\n",
            "Epoch 073 | loss: 0.6874 | Validation score: 0.5274 | Test score: 0.5335\n",
            "Epoch 074 | loss: 0.6873 | Validation score: 0.5274 | Test score: 0.5339\n",
            "Epoch 075 | loss: 0.6873 | Validation score: 0.5274 | Test score: 0.5339\n",
            "Epoch 076 | loss: 0.6872 | Validation score: 0.5274 | Test score: 0.5339\n",
            "Epoch 077 | loss: 0.6872 | Validation score: 0.5274 | Test score: 0.5339\n",
            "Epoch 078 | loss: 0.6870 | Validation score: 0.5274 | Test score: 0.5335\n",
            "Epoch 079 | loss: 0.6872 | Validation score: 0.5276 | Test score: 0.5335\n",
            "Epoch 080 | loss: 0.6871 | Validation score: 0.5276 | Test score: 0.5347\n",
            "Epoch 081 | loss: 0.6871 | Validation score: 0.5276 | Test score: 0.5347\n",
            "Epoch 082 | loss: 0.6868 | Validation score: 0.5276 | Test score: 0.5359\n",
            "Epoch 083 | loss: 0.6871 | Validation score: 0.5280 | Test score: 0.5351\n",
            "Epoch 084 | loss: 0.6868 | Validation score: 0.5280 | Test score: 0.5355\n",
            "Epoch 085 | loss: 0.6870 | Validation score: 0.5280 | Test score: 0.5363\n",
            "Epoch 086 | loss: 0.6869 | Validation score: 0.5278 | Test score: 0.5363\n",
            "Epoch 087 | loss: 0.6869 | Validation score: 0.5276 | Test score: 0.5371\n",
            "Epoch 088 | loss: 0.6867 | Validation score: 0.5274 | Test score: 0.5371\n",
            "Epoch 089 | loss: 0.6867 | Validation score: 0.5276 | Test score: 0.5367\n",
            "Epoch 090 | loss: 0.6865 | Validation score: 0.5280 | Test score: 0.5367\n",
            "Epoch 091 | loss: 0.6867 | Validation score: 0.5283 | Test score: 0.5371\n",
            "Epoch 092 | loss: 0.6866 | Validation score: 0.5287 | Test score: 0.5387\n",
            "Epoch 093 | loss: 0.6866 | Validation score: 0.5283 | Test score: 0.5387\n",
            "Epoch 094 | loss: 0.6864 | Validation score: 0.5285 | Test score: 0.5387\n",
            "Epoch 095 | loss: 0.6865 | Validation score: 0.5294 | Test score: 0.5391\n",
            "Epoch 096 | loss: 0.6864 | Validation score: 0.5296 | Test score: 0.5391\n",
            "Epoch 097 | loss: 0.6863 | Validation score: 0.5290 | Test score: 0.5395\n",
            "Epoch 098 | loss: 0.6861 | Validation score: 0.5294 | Test score: 0.5391\n",
            "Epoch 099 | loss: 0.6863 | Validation score: 0.5294 | Test score: 0.5391\n",
            "Epoch 100 | loss: 0.6862 | Validation score: 0.5296 | Test score: 0.5387\n",
            "Epoch 101 | loss: 0.6864 | Validation score: 0.5296 | Test score: 0.5391\n",
            "Epoch 102 | loss: 0.6862 | Validation score: 0.5294 | Test score: 0.5399\n",
            "Epoch 103 | loss: 0.6864 | Validation score: 0.5296 | Test score: 0.5415\n",
            "Epoch 104 | loss: 0.6862 | Validation score: 0.5294 | Test score: 0.5423\n",
            "Epoch 105 | loss: 0.6862 | Validation score: 0.5292 | Test score: 0.5431\n",
            "Epoch 106 | loss: 0.6860 | Validation score: 0.5287 | Test score: 0.5431\n",
            "Epoch 107 | loss: 0.6862 | Validation score: 0.5285 | Test score: 0.5431\n",
            "Epoch 108 | loss: 0.6861 | Validation score: 0.5285 | Test score: 0.5435\n",
            "Epoch 109 | loss: 0.6861 | Validation score: 0.5283 | Test score: 0.5435\n",
            "Epoch 110 | loss: 0.6859 | Validation score: 0.5285 | Test score: 0.5448\n",
            "Epoch 111 | loss: 0.6859 | Validation score: 0.5280 | Test score: 0.5448\n",
            "Epoch 112 | loss: 0.6859 | Validation score: 0.5278 | Test score: 0.5460\n",
            "Epoch 113 | loss: 0.6861 | Validation score: 0.5283 | Test score: 0.5460\n",
            "Epoch 114 | loss: 0.6857 | Validation score: 0.5280 | Test score: 0.5476\n",
            "Epoch 115 | loss: 0.6859 | Validation score: 0.5285 | Test score: 0.5488\n",
            "Epoch 116 | loss: 0.6856 | Validation score: 0.5283 | Test score: 0.5504\n",
            "Epoch 117 | loss: 0.6857 | Validation score: 0.5276 | Test score: 0.5512\n",
            "Epoch 118 | loss: 0.6858 | Validation score: 0.5287 | Test score: 0.5540\n",
            "Epoch 119 | loss: 0.6859 | Validation score: 0.5294 | Test score: 0.5552\n",
            "Epoch 120 | loss: 0.6855 | Validation score: 0.5299 | Test score: 0.5560\n",
            "Epoch 121 | loss: 0.6856 | Validation score: 0.5294 | Test score: 0.5560\n",
            "Epoch 122 | loss: 0.6854 | Validation score: 0.5296 | Test score: 0.5548\n",
            "Epoch 123 | loss: 0.6855 | Validation score: 0.5301 | Test score: 0.5552\n",
            "Epoch 124 | loss: 0.6856 | Validation score: 0.5303 | Test score: 0.5560\n",
            "Epoch 125 | loss: 0.6854 | Validation score: 0.5301 | Test score: 0.5556\n",
            "Epoch 126 | loss: 0.6855 | Validation score: 0.5310 | Test score: 0.5560\n",
            "Epoch 127 | loss: 0.6855 | Validation score: 0.5308 | Test score: 0.5577\n",
            "Epoch 128 | loss: 0.6854 | Validation score: 0.5310 | Test score: 0.5581\n",
            "Epoch 129 | loss: 0.6852 | Validation score: 0.5312 | Test score: 0.5601\n",
            "Epoch 130 | loss: 0.6852 | Validation score: 0.5331 | Test score: 0.5605\n",
            "Epoch 131 | loss: 0.6852 | Validation score: 0.5324 | Test score: 0.5621\n",
            "Epoch 132 | loss: 0.6851 | Validation score: 0.5333 | Test score: 0.5629\n",
            "Epoch 133 | loss: 0.6852 | Validation score: 0.5331 | Test score: 0.5625\n",
            "Epoch 134 | loss: 0.6851 | Validation score: 0.5328 | Test score: 0.5641\n",
            "Epoch 135 | loss: 0.6851 | Validation score: 0.5342 | Test score: 0.5641\n",
            "Epoch 136 | loss: 0.6848 | Validation score: 0.5342 | Test score: 0.5645\n",
            "Epoch 137 | loss: 0.6849 | Validation score: 0.5353 | Test score: 0.5649\n",
            "Epoch 138 | loss: 0.6849 | Validation score: 0.5351 | Test score: 0.5653\n",
            "Epoch 139 | loss: 0.6851 | Validation score: 0.5349 | Test score: 0.5661\n",
            "Epoch 140 | loss: 0.6849 | Validation score: 0.5358 | Test score: 0.5677\n",
            "Epoch 141 | loss: 0.6850 | Validation score: 0.5353 | Test score: 0.5661\n",
            "Epoch 142 | loss: 0.6848 | Validation score: 0.5349 | Test score: 0.5661\n",
            "Epoch 143 | loss: 0.6848 | Validation score: 0.5347 | Test score: 0.5681\n",
            "Epoch 144 | loss: 0.6849 | Validation score: 0.5349 | Test score: 0.5685\n",
            "Epoch 145 | loss: 0.6846 | Validation score: 0.5360 | Test score: 0.5698\n",
            "Epoch 146 | loss: 0.6847 | Validation score: 0.5356 | Test score: 0.5702\n",
            "Epoch 147 | loss: 0.6845 | Validation score: 0.5358 | Test score: 0.5722\n",
            "Epoch 148 | loss: 0.6846 | Validation score: 0.5363 | Test score: 0.5734\n",
            "Epoch 149 | loss: 0.6847 | Validation score: 0.5363 | Test score: 0.5762\n",
            "Epoch 150 | loss: 0.6845 | Validation score: 0.5369 | Test score: 0.5754\n",
            "Epoch 151 | loss: 0.6846 | Validation score: 0.5365 | Test score: 0.5746\n",
            "Epoch 152 | loss: 0.6844 | Validation score: 0.5381 | Test score: 0.5758\n",
            "Epoch 153 | loss: 0.6844 | Validation score: 0.5376 | Test score: 0.5770\n",
            "Epoch 154 | loss: 0.6845 | Validation score: 0.5372 | Test score: 0.5786\n",
            "Epoch 155 | loss: 0.6842 | Validation score: 0.5372 | Test score: 0.5786\n",
            "Epoch 156 | loss: 0.6843 | Validation score: 0.5381 | Test score: 0.5794\n",
            "Epoch 157 | loss: 0.6841 | Validation score: 0.5383 | Test score: 0.5798\n",
            "Epoch 158 | loss: 0.6845 | Validation score: 0.5367 | Test score: 0.5798\n",
            "Epoch 159 | loss: 0.6844 | Validation score: 0.5367 | Test score: 0.5810\n",
            "Epoch 160 | loss: 0.6844 | Validation score: 0.5365 | Test score: 0.5810\n",
            "Epoch 161 | loss: 0.6844 | Validation score: 0.5365 | Test score: 0.5819\n",
            "Epoch 162 | loss: 0.6842 | Validation score: 0.5376 | Test score: 0.5810\n",
            "Epoch 163 | loss: 0.6842 | Validation score: 0.5383 | Test score: 0.5810\n",
            "Epoch 164 | loss: 0.6842 | Validation score: 0.5383 | Test score: 0.5815\n",
            "Epoch 165 | loss: 0.6844 | Validation score: 0.5383 | Test score: 0.5831\n",
            "Epoch 166 | loss: 0.6841 | Validation score: 0.5388 | Test score: 0.5847\n",
            "Epoch 167 | loss: 0.6842 | Validation score: 0.5388 | Test score: 0.5839\n",
            "Epoch 168 | loss: 0.6843 | Validation score: 0.5390 | Test score: 0.5855\n",
            "Epoch 169 | loss: 0.6842 | Validation score: 0.5392 | Test score: 0.5859\n",
            "Epoch 170 | loss: 0.6838 | Validation score: 0.5399 | Test score: 0.5871\n",
            "Epoch 171 | loss: 0.6838 | Validation score: 0.5404 | Test score: 0.5863\n",
            "Epoch 172 | loss: 0.6839 | Validation score: 0.5404 | Test score: 0.5847\n",
            "Epoch 173 | loss: 0.6837 | Validation score: 0.5397 | Test score: 0.5855\n",
            "Epoch 174 | loss: 0.6839 | Validation score: 0.5406 | Test score: 0.5843\n",
            "Epoch 175 | loss: 0.6837 | Validation score: 0.5392 | Test score: 0.5847\n",
            "Epoch 176 | loss: 0.6838 | Validation score: 0.5390 | Test score: 0.5839\n",
            "Epoch 177 | loss: 0.6839 | Validation score: 0.5390 | Test score: 0.5839\n",
            "Epoch 178 | loss: 0.6839 | Validation score: 0.5392 | Test score: 0.5843\n",
            "Epoch 179 | loss: 0.6839 | Validation score: 0.5388 | Test score: 0.5851\n",
            "Epoch 180 | loss: 0.6839 | Validation score: 0.5392 | Test score: 0.5859\n",
            "Epoch 181 | loss: 0.6836 | Validation score: 0.5388 | Test score: 0.5855\n",
            "Epoch 182 | loss: 0.6838 | Validation score: 0.5390 | Test score: 0.5859\n",
            "Epoch 183 | loss: 0.6836 | Validation score: 0.5397 | Test score: 0.5875\n",
            "Epoch 184 | loss: 0.6838 | Validation score: 0.5392 | Test score: 0.5879\n",
            "Epoch 185 | loss: 0.6836 | Validation score: 0.5397 | Test score: 0.5895\n",
            "Epoch 186 | loss: 0.6835 | Validation score: 0.5392 | Test score: 0.5891\n",
            "Epoch 187 | loss: 0.6835 | Validation score: 0.5385 | Test score: 0.5895\n",
            "Epoch 188 | loss: 0.6834 | Validation score: 0.5383 | Test score: 0.5907\n",
            "Epoch 189 | loss: 0.6834 | Validation score: 0.5383 | Test score: 0.5915\n",
            "Epoch 190 | loss: 0.6836 | Validation score: 0.5383 | Test score: 0.5923\n",
            "Epoch 191 | loss: 0.6835 | Validation score: 0.5388 | Test score: 0.5931\n",
            "Epoch 192 | loss: 0.6834 | Validation score: 0.5390 | Test score: 0.5927\n",
            "Epoch 193 | loss: 0.6831 | Validation score: 0.5388 | Test score: 0.5911\n",
            "Epoch 194 | loss: 0.6834 | Validation score: 0.5374 | Test score: 0.5907\n",
            "Epoch 195 | loss: 0.6837 | Validation score: 0.5374 | Test score: 0.5907\n",
            "Epoch 196 | loss: 0.6834 | Validation score: 0.5376 | Test score: 0.5907\n",
            "Epoch 197 | loss: 0.6832 | Validation score: 0.5381 | Test score: 0.5907\n",
            "Epoch 198 | loss: 0.6836 | Validation score: 0.5381 | Test score: 0.5915\n",
            "Epoch 199 | loss: 0.6836 | Validation score: 0.5376 | Test score: 0.5911\n",
            "Epoch 200 | loss: 0.6833 | Validation score: 0.5378 | Test score: 0.5911\n",
            "Epoch 201 | loss: 0.6833 | Validation score: 0.5383 | Test score: 0.5907\n",
            "Epoch 202 | loss: 0.6834 | Validation score: 0.5383 | Test score: 0.5903\n",
            "Epoch 203 | loss: 0.6833 | Validation score: 0.5385 | Test score: 0.5907\n",
            "Epoch 204 | loss: 0.6834 | Validation score: 0.5390 | Test score: 0.5891\n",
            "Epoch 205 | loss: 0.6832 | Validation score: 0.5388 | Test score: 0.5891\n",
            "Epoch 206 | loss: 0.6833 | Validation score: 0.5388 | Test score: 0.5899\n",
            "Epoch 207 | loss: 0.6834 | Validation score: 0.5385 | Test score: 0.5899\n",
            "Epoch 208 | loss: 0.6832 | Validation score: 0.5381 | Test score: 0.5895\n",
            "Epoch 209 | loss: 0.6831 | Validation score: 0.5385 | Test score: 0.5899\n",
            "Epoch 210 | loss: 0.6828 | Validation score: 0.5383 | Test score: 0.5895\n",
            "Epoch 211 | loss: 0.6832 | Validation score: 0.5385 | Test score: 0.5895\n",
            "Epoch 212 | loss: 0.6833 | Validation score: 0.5381 | Test score: 0.5899\n",
            "Epoch 213 | loss: 0.6833 | Validation score: 0.5381 | Test score: 0.5895\n",
            "Epoch 214 | loss: 0.6831 | Validation score: 0.5376 | Test score: 0.5903\n",
            "Epoch 215 | loss: 0.6828 | Validation score: 0.5372 | Test score: 0.5907\n",
            "Epoch 216 | loss: 0.6832 | Validation score: 0.5367 | Test score: 0.5911\n",
            "Epoch 217 | loss: 0.6831 | Validation score: 0.5381 | Test score: 0.5911\n",
            "Epoch 218 | loss: 0.6832 | Validation score: 0.5378 | Test score: 0.5923\n",
            "Epoch 219 | loss: 0.6829 | Validation score: 0.5385 | Test score: 0.5931\n",
            "Epoch 220 | loss: 0.6831 | Validation score: 0.5388 | Test score: 0.5931\n",
            "Epoch 221 | loss: 0.6828 | Validation score: 0.5388 | Test score: 0.5940\n",
            "Epoch 222 | loss: 0.6832 | Validation score: 0.5394 | Test score: 0.5935\n",
            "Epoch 223 | loss: 0.6832 | Validation score: 0.5401 | Test score: 0.5935\n",
            "Epoch 224 | loss: 0.6831 | Validation score: 0.5406 | Test score: 0.5935\n",
            "Epoch 225 | loss: 0.6828 | Validation score: 0.5408 | Test score: 0.5940\n",
            "Epoch 226 | loss: 0.6831 | Validation score: 0.5408 | Test score: 0.5948\n",
            "Epoch 227 | loss: 0.6830 | Validation score: 0.5401 | Test score: 0.5952\n",
            "Epoch 228 | loss: 0.6831 | Validation score: 0.5406 | Test score: 0.5948\n",
            "Epoch 229 | loss: 0.6831 | Validation score: 0.5408 | Test score: 0.5956\n",
            "Epoch 230 | loss: 0.6827 | Validation score: 0.5406 | Test score: 0.5952\n",
            "Epoch 231 | loss: 0.6827 | Validation score: 0.5408 | Test score: 0.5948\n",
            "Epoch 232 | loss: 0.6827 | Validation score: 0.5410 | Test score: 0.5948\n",
            "Epoch 233 | loss: 0.6829 | Validation score: 0.5406 | Test score: 0.5944\n",
            "Epoch 234 | loss: 0.6826 | Validation score: 0.5406 | Test score: 0.5944\n",
            "Epoch 235 | loss: 0.6829 | Validation score: 0.5399 | Test score: 0.5940\n",
            "Epoch 236 | loss: 0.6828 | Validation score: 0.5401 | Test score: 0.5948\n",
            "Epoch 237 | loss: 0.6825 | Validation score: 0.5404 | Test score: 0.5948\n",
            "Epoch 238 | loss: 0.6825 | Validation score: 0.5406 | Test score: 0.5956\n",
            "Epoch 239 | loss: 0.6826 | Validation score: 0.5399 | Test score: 0.5952\n",
            "Epoch 240 | loss: 0.6829 | Validation score: 0.5401 | Test score: 0.5952\n",
            "Epoch 241 | loss: 0.6826 | Validation score: 0.5401 | Test score: 0.5940\n",
            "Epoch 242 | loss: 0.6828 | Validation score: 0.5392 | Test score: 0.5940\n",
            "Epoch 243 | loss: 0.6830 | Validation score: 0.5385 | Test score: 0.5940\n",
            "Epoch 244 | loss: 0.6826 | Validation score: 0.5385 | Test score: 0.5948\n",
            "Epoch 245 | loss: 0.6823 | Validation score: 0.5381 | Test score: 0.5944\n",
            "Epoch 246 | loss: 0.6828 | Validation score: 0.5381 | Test score: 0.5952\n",
            "Epoch 247 | loss: 0.6826 | Validation score: 0.5385 | Test score: 0.5952\n",
            "Epoch 248 | loss: 0.6825 | Validation score: 0.5381 | Test score: 0.5952\n",
            "Epoch 249 | loss: 0.6824 | Validation score: 0.5378 | Test score: 0.5956\n",
            "Epoch 250 | loss: 0.6827 | Validation score: 0.5383 | Test score: 0.5956\n",
            "Epoch 251 | loss: 0.6825 | Validation score: 0.5383 | Test score: 0.5964\n",
            "Epoch 252 | loss: 0.6828 | Validation score: 0.5381 | Test score: 0.5952\n",
            "Epoch 253 | loss: 0.6826 | Validation score: 0.5381 | Test score: 0.5952\n",
            "Epoch 254 | loss: 0.6824 | Validation score: 0.5388 | Test score: 0.5956\n",
            "Epoch 255 | loss: 0.6826 | Validation score: 0.5383 | Test score: 0.5952\n",
            "Epoch 256 | loss: 0.6825 | Validation score: 0.5388 | Test score: 0.5944\n",
            "Epoch 257 | loss: 0.6827 | Validation score: 0.5383 | Test score: 0.5944\n",
            "Epoch 258 | loss: 0.6823 | Validation score: 0.5399 | Test score: 0.5944\n",
            "Epoch 259 | loss: 0.6827 | Validation score: 0.5401 | Test score: 0.5944\n",
            "Epoch 260 | loss: 0.6824 | Validation score: 0.5404 | Test score: 0.5940\n",
            "Epoch 261 | loss: 0.6826 | Validation score: 0.5406 | Test score: 0.5940\n",
            "Epoch 262 | loss: 0.6828 | Validation score: 0.5408 | Test score: 0.5948\n",
            "Epoch 263 | loss: 0.6826 | Validation score: 0.5410 | Test score: 0.5944\n",
            "Epoch 264 | loss: 0.6826 | Validation score: 0.5406 | Test score: 0.5952\n",
            "Epoch 265 | loss: 0.6824 | Validation score: 0.5408 | Test score: 0.5956\n",
            "Epoch 266 | loss: 0.6821 | Validation score: 0.5413 | Test score: 0.5952\n",
            "Epoch 267 | loss: 0.6823 | Validation score: 0.5420 | Test score: 0.5952\n",
            "Epoch 268 | loss: 0.6825 | Validation score: 0.5420 | Test score: 0.5952\n",
            "Epoch 269 | loss: 0.6821 | Validation score: 0.5426 | Test score: 0.5956\n",
            "Epoch 270 | loss: 0.6827 | Validation score: 0.5429 | Test score: 0.5956\n",
            "Epoch 271 | loss: 0.6825 | Validation score: 0.5431 | Test score: 0.5956\n",
            "Epoch 272 | loss: 0.6826 | Validation score: 0.5433 | Test score: 0.5952\n",
            "Epoch 273 | loss: 0.6825 | Validation score: 0.5438 | Test score: 0.5952\n",
            "Epoch 274 | loss: 0.6822 | Validation score: 0.5440 | Test score: 0.5952\n",
            "Epoch 275 | loss: 0.6823 | Validation score: 0.5438 | Test score: 0.5952\n",
            "Epoch 276 | loss: 0.6822 | Validation score: 0.5438 | Test score: 0.5956\n",
            "Epoch 277 | loss: 0.6827 | Validation score: 0.5438 | Test score: 0.5964\n",
            "Epoch 278 | loss: 0.6825 | Validation score: 0.5438 | Test score: 0.5964\n",
            "Epoch 279 | loss: 0.6822 | Validation score: 0.5442 | Test score: 0.5960\n",
            "Epoch 280 | loss: 0.6826 | Validation score: 0.5445 | Test score: 0.5968\n",
            "Epoch 281 | loss: 0.6825 | Validation score: 0.5438 | Test score: 0.5972\n",
            "Epoch 282 | loss: 0.6823 | Validation score: 0.5438 | Test score: 0.5972\n",
            "Epoch 283 | loss: 0.6823 | Validation score: 0.5440 | Test score: 0.5964\n",
            "Epoch 284 | loss: 0.6822 | Validation score: 0.5440 | Test score: 0.5964\n",
            "Epoch 285 | loss: 0.6826 | Validation score: 0.5440 | Test score: 0.5964\n",
            "Epoch 286 | loss: 0.6824 | Validation score: 0.5438 | Test score: 0.5968\n",
            "Epoch 287 | loss: 0.6826 | Validation score: 0.5442 | Test score: 0.5968\n",
            "Epoch 288 | loss: 0.6823 | Validation score: 0.5442 | Test score: 0.5968\n",
            "Epoch 289 | loss: 0.6821 | Validation score: 0.5440 | Test score: 0.5972\n",
            "Epoch 290 | loss: 0.6821 | Validation score: 0.5445 | Test score: 0.5968\n",
            "Epoch 291 | loss: 0.6822 | Validation score: 0.5447 | Test score: 0.5972\n",
            "Epoch 292 | loss: 0.6821 | Validation score: 0.5449 | Test score: 0.5972\n",
            "Epoch 293 | loss: 0.6824 | Validation score: 0.5447 | Test score: 0.5972\n",
            "Epoch 294 | loss: 0.6821 | Validation score: 0.5442 | Test score: 0.5968\n",
            "Epoch 295 | loss: 0.6820 | Validation score: 0.5447 | Test score: 0.5968\n",
            "Epoch 296 | loss: 0.6819 | Validation score: 0.5451 | Test score: 0.5968\n",
            "Epoch 297 | loss: 0.6821 | Validation score: 0.5449 | Test score: 0.5972\n",
            "Epoch 298 | loss: 0.6823 | Validation score: 0.5451 | Test score: 0.5976\n",
            "Epoch 299 | loss: 0.6824 | Validation score: 0.5454 | Test score: 0.5976\n",
            "Epoch 300 | loss: 0.6820 | Validation score: 0.5454 | Test score: 0.5972\n",
            "Epoch 301 | loss: 0.6818 | Validation score: 0.5456 | Test score: 0.5972\n",
            "Epoch 302 | loss: 0.6821 | Validation score: 0.5465 | Test score: 0.5976\n",
            "Epoch 303 | loss: 0.6821 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 304 | loss: 0.6825 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 305 | loss: 0.6819 | Validation score: 0.5465 | Test score: 0.5972\n",
            "Epoch 306 | loss: 0.6823 | Validation score: 0.5463 | Test score: 0.5968\n",
            "Epoch 307 | loss: 0.6823 | Validation score: 0.5458 | Test score: 0.5972\n",
            "Epoch 308 | loss: 0.6821 | Validation score: 0.5465 | Test score: 0.5972\n",
            "Epoch 309 | loss: 0.6822 | Validation score: 0.5463 | Test score: 0.5972\n",
            "Epoch 310 | loss: 0.6822 | Validation score: 0.5463 | Test score: 0.5976\n",
            "Epoch 311 | loss: 0.6823 | Validation score: 0.5463 | Test score: 0.5972\n",
            "Epoch 312 | loss: 0.6820 | Validation score: 0.5465 | Test score: 0.5972\n",
            "Epoch 313 | loss: 0.6821 | Validation score: 0.5465 | Test score: 0.5972\n",
            "Epoch 314 | loss: 0.6821 | Validation score: 0.5461 | Test score: 0.5968\n",
            "Epoch 315 | loss: 0.6820 | Validation score: 0.5461 | Test score: 0.5968\n",
            "Epoch 316 | loss: 0.6820 | Validation score: 0.5456 | Test score: 0.5968\n",
            "Epoch 317 | loss: 0.6822 | Validation score: 0.5458 | Test score: 0.5968\n",
            "Epoch 318 | loss: 0.6821 | Validation score: 0.5458 | Test score: 0.5968\n",
            "Epoch 319 | loss: 0.6821 | Validation score: 0.5461 | Test score: 0.5968\n",
            "Epoch 320 | loss: 0.6819 | Validation score: 0.5461 | Test score: 0.5972\n",
            "Epoch 321 | loss: 0.6821 | Validation score: 0.5458 | Test score: 0.5972\n",
            "Epoch 322 | loss: 0.6820 | Validation score: 0.5458 | Test score: 0.5968\n",
            "Epoch 323 | loss: 0.6822 | Validation score: 0.5458 | Test score: 0.5968\n",
            "Epoch 324 | loss: 0.6821 | Validation score: 0.5461 | Test score: 0.5968\n",
            "Epoch 325 | loss: 0.6822 | Validation score: 0.5458 | Test score: 0.5976\n",
            "Epoch 326 | loss: 0.6820 | Validation score: 0.5467 | Test score: 0.5976\n",
            "Epoch 327 | loss: 0.6819 | Validation score: 0.5465 | Test score: 0.5976\n",
            "Epoch 328 | loss: 0.6821 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 329 | loss: 0.6822 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 330 | loss: 0.6823 | Validation score: 0.5472 | Test score: 0.5968\n",
            "Epoch 331 | loss: 0.6820 | Validation score: 0.5472 | Test score: 0.5968\n",
            "Epoch 332 | loss: 0.6821 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 333 | loss: 0.6820 | Validation score: 0.5467 | Test score: 0.5968\n",
            "Epoch 334 | loss: 0.6821 | Validation score: 0.5467 | Test score: 0.5960\n",
            "Epoch 335 | loss: 0.6821 | Validation score: 0.5470 | Test score: 0.5960\n",
            "Epoch 336 | loss: 0.6821 | Validation score: 0.5470 | Test score: 0.5960\n",
            "Epoch 337 | loss: 0.6817 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 338 | loss: 0.6819 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 339 | loss: 0.6818 | Validation score: 0.5465 | Test score: 0.5952\n",
            "Epoch 340 | loss: 0.6822 | Validation score: 0.5467 | Test score: 0.5948\n",
            "Epoch 341 | loss: 0.6819 | Validation score: 0.5467 | Test score: 0.5948\n",
            "Epoch 342 | loss: 0.6821 | Validation score: 0.5465 | Test score: 0.5948\n",
            "Epoch 343 | loss: 0.6816 | Validation score: 0.5463 | Test score: 0.5948\n",
            "Epoch 344 | loss: 0.6821 | Validation score: 0.5461 | Test score: 0.5948\n",
            "Epoch 345 | loss: 0.6820 | Validation score: 0.5458 | Test score: 0.5944\n",
            "Epoch 346 | loss: 0.6817 | Validation score: 0.5458 | Test score: 0.5944\n",
            "Epoch 347 | loss: 0.6820 | Validation score: 0.5454 | Test score: 0.5935\n",
            "Epoch 348 | loss: 0.6818 | Validation score: 0.5454 | Test score: 0.5935\n",
            "Epoch 349 | loss: 0.6820 | Validation score: 0.5451 | Test score: 0.5935\n",
            "Epoch 350 | loss: 0.6820 | Validation score: 0.5451 | Test score: 0.5935\n",
            "Epoch 351 | loss: 0.6818 | Validation score: 0.5449 | Test score: 0.5935\n",
            "Epoch 352 | loss: 0.6823 | Validation score: 0.5449 | Test score: 0.5935\n",
            "Epoch 353 | loss: 0.6820 | Validation score: 0.5447 | Test score: 0.5935\n",
            "Epoch 354 | loss: 0.6818 | Validation score: 0.5445 | Test score: 0.5940\n",
            "Epoch 355 | loss: 0.6818 | Validation score: 0.5445 | Test score: 0.5935\n",
            "Epoch 356 | loss: 0.6818 | Validation score: 0.5442 | Test score: 0.5935\n",
            "Epoch 357 | loss: 0.6822 | Validation score: 0.5442 | Test score: 0.5940\n",
            "Epoch 358 | loss: 0.6820 | Validation score: 0.5442 | Test score: 0.5940\n",
            "Epoch 359 | loss: 0.6818 | Validation score: 0.5445 | Test score: 0.5940\n",
            "Epoch 360 | loss: 0.6819 | Validation score: 0.5447 | Test score: 0.5940\n",
            "Epoch 361 | loss: 0.6818 | Validation score: 0.5449 | Test score: 0.5940\n",
            "Epoch 362 | loss: 0.6818 | Validation score: 0.5449 | Test score: 0.5948\n",
            "Epoch 363 | loss: 0.6822 | Validation score: 0.5447 | Test score: 0.5948\n",
            "Epoch 364 | loss: 0.6819 | Validation score: 0.5442 | Test score: 0.5948\n",
            "Epoch 365 | loss: 0.6817 | Validation score: 0.5445 | Test score: 0.5948\n",
            "Epoch 366 | loss: 0.6816 | Validation score: 0.5445 | Test score: 0.5944\n",
            "Epoch 367 | loss: 0.6818 | Validation score: 0.5445 | Test score: 0.5944\n",
            "Epoch 368 | loss: 0.6820 | Validation score: 0.5445 | Test score: 0.5944\n",
            "Epoch 369 | loss: 0.6818 | Validation score: 0.5447 | Test score: 0.5944\n",
            "Epoch 370 | loss: 0.6820 | Validation score: 0.5451 | Test score: 0.5944\n",
            "Epoch 371 | loss: 0.6820 | Validation score: 0.5458 | Test score: 0.5940\n",
            "Epoch 372 | loss: 0.6819 | Validation score: 0.5458 | Test score: 0.5935\n",
            "Epoch 373 | loss: 0.6821 | Validation score: 0.5458 | Test score: 0.5935\n",
            "Epoch 374 | loss: 0.6819 | Validation score: 0.5458 | Test score: 0.5935\n",
            "Epoch 375 | loss: 0.6820 | Validation score: 0.5463 | Test score: 0.5935\n",
            "Epoch 376 | loss: 0.6819 | Validation score: 0.5461 | Test score: 0.5940\n",
            "Epoch 377 | loss: 0.6819 | Validation score: 0.5463 | Test score: 0.5935\n",
            "Epoch 378 | loss: 0.6819 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 379 | loss: 0.6819 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 380 | loss: 0.6820 | Validation score: 0.5467 | Test score: 0.5935\n",
            "Epoch 381 | loss: 0.6820 | Validation score: 0.5470 | Test score: 0.5944\n",
            "Epoch 382 | loss: 0.6816 | Validation score: 0.5463 | Test score: 0.5940\n",
            "Epoch 383 | loss: 0.6814 | Validation score: 0.5463 | Test score: 0.5940\n",
            "Epoch 384 | loss: 0.6818 | Validation score: 0.5463 | Test score: 0.5944\n",
            "Epoch 385 | loss: 0.6820 | Validation score: 0.5467 | Test score: 0.5948\n",
            "Epoch 386 | loss: 0.6818 | Validation score: 0.5467 | Test score: 0.5948\n",
            "Epoch 387 | loss: 0.6816 | Validation score: 0.5467 | Test score: 0.5948\n",
            "Epoch 388 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5952\n",
            "Epoch 389 | loss: 0.6821 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 390 | loss: 0.6817 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 391 | loss: 0.6818 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 392 | loss: 0.6817 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 393 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5948\n",
            "Epoch 394 | loss: 0.6817 | Validation score: 0.5470 | Test score: 0.5948\n",
            "Epoch 395 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5948\n",
            "Epoch 396 | loss: 0.6818 | Validation score: 0.5467 | Test score: 0.5948\n",
            "Epoch 397 | loss: 0.6817 | Validation score: 0.5465 | Test score: 0.5948\n",
            "Epoch 398 | loss: 0.6818 | Validation score: 0.5465 | Test score: 0.5948\n",
            "Epoch 399 | loss: 0.6820 | Validation score: 0.5465 | Test score: 0.5940\n",
            "Epoch 400 | loss: 0.6816 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 401 | loss: 0.6817 | Validation score: 0.5461 | Test score: 0.5935\n",
            "Epoch 402 | loss: 0.6818 | Validation score: 0.5461 | Test score: 0.5935\n",
            "Epoch 403 | loss: 0.6820 | Validation score: 0.5463 | Test score: 0.5935\n",
            "Epoch 404 | loss: 0.6820 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 405 | loss: 0.6819 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 406 | loss: 0.6818 | Validation score: 0.5463 | Test score: 0.5935\n",
            "Epoch 407 | loss: 0.6817 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 408 | loss: 0.6815 | Validation score: 0.5465 | Test score: 0.5931\n",
            "Epoch 409 | loss: 0.6817 | Validation score: 0.5465 | Test score: 0.5931\n",
            "Epoch 410 | loss: 0.6818 | Validation score: 0.5465 | Test score: 0.5931\n",
            "Epoch 411 | loss: 0.6818 | Validation score: 0.5465 | Test score: 0.5931\n",
            "Epoch 412 | loss: 0.6818 | Validation score: 0.5465 | Test score: 0.5931\n",
            "Epoch 413 | loss: 0.6819 | Validation score: 0.5467 | Test score: 0.5931\n",
            "Epoch 414 | loss: 0.6818 | Validation score: 0.5467 | Test score: 0.5931\n",
            "Epoch 415 | loss: 0.6816 | Validation score: 0.5467 | Test score: 0.5935\n",
            "Epoch 416 | loss: 0.6815 | Validation score: 0.5467 | Test score: 0.5935\n",
            "Epoch 417 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5935\n",
            "Epoch 418 | loss: 0.6821 | Validation score: 0.5467 | Test score: 0.5935\n",
            "Epoch 419 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5935\n",
            "Epoch 420 | loss: 0.6819 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 421 | loss: 0.6816 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 422 | loss: 0.6821 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 423 | loss: 0.6815 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 424 | loss: 0.6821 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 425 | loss: 0.6820 | Validation score: 0.5467 | Test score: 0.5935\n",
            "Epoch 426 | loss: 0.6816 | Validation score: 0.5467 | Test score: 0.5935\n",
            "Epoch 427 | loss: 0.6819 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 428 | loss: 0.6817 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 429 | loss: 0.6818 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 430 | loss: 0.6821 | Validation score: 0.5465 | Test score: 0.5935\n",
            "Epoch 431 | loss: 0.6812 | Validation score: 0.5465 | Test score: 0.5944\n",
            "Epoch 432 | loss: 0.6817 | Validation score: 0.5465 | Test score: 0.5944\n",
            "Epoch 433 | loss: 0.6819 | Validation score: 0.5463 | Test score: 0.5944\n",
            "Epoch 434 | loss: 0.6813 | Validation score: 0.5463 | Test score: 0.5944\n",
            "Epoch 435 | loss: 0.6813 | Validation score: 0.5465 | Test score: 0.5944\n",
            "Epoch 436 | loss: 0.6817 | Validation score: 0.5465 | Test score: 0.5944\n",
            "Epoch 437 | loss: 0.6818 | Validation score: 0.5463 | Test score: 0.5948\n",
            "Epoch 438 | loss: 0.6815 | Validation score: 0.5463 | Test score: 0.5948\n",
            "Epoch 439 | loss: 0.6817 | Validation score: 0.5463 | Test score: 0.5952\n",
            "Epoch 440 | loss: 0.6817 | Validation score: 0.5463 | Test score: 0.5952\n",
            "Epoch 441 | loss: 0.6815 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 442 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 443 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 444 | loss: 0.6815 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 445 | loss: 0.6819 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 446 | loss: 0.6816 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 447 | loss: 0.6818 | Validation score: 0.5470 | Test score: 0.5956\n",
            "Epoch 448 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 449 | loss: 0.6816 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 450 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 451 | loss: 0.6820 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 452 | loss: 0.6817 | Validation score: 0.5465 | Test score: 0.5956\n",
            "Epoch 453 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 454 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 455 | loss: 0.6818 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 456 | loss: 0.6813 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 457 | loss: 0.6820 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 458 | loss: 0.6818 | Validation score: 0.5470 | Test score: 0.5956\n",
            "Epoch 459 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5956\n",
            "Epoch 460 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 461 | loss: 0.6815 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 462 | loss: 0.6816 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 463 | loss: 0.6816 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 464 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5952\n",
            "Epoch 465 | loss: 0.6816 | Validation score: 0.5479 | Test score: 0.5952\n",
            "Epoch 466 | loss: 0.6820 | Validation score: 0.5477 | Test score: 0.5952\n",
            "Epoch 467 | loss: 0.6819 | Validation score: 0.5477 | Test score: 0.5952\n",
            "Epoch 468 | loss: 0.6817 | Validation score: 0.5477 | Test score: 0.5952\n",
            "Epoch 469 | loss: 0.6817 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 470 | loss: 0.6819 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 471 | loss: 0.6820 | Validation score: 0.5477 | Test score: 0.5952\n",
            "Epoch 472 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 473 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 474 | loss: 0.6817 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 475 | loss: 0.6817 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 476 | loss: 0.6816 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 477 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 478 | loss: 0.6817 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 479 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 480 | loss: 0.6819 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 481 | loss: 0.6816 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 482 | loss: 0.6817 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 483 | loss: 0.6816 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 484 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5956\n",
            "Epoch 485 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5956\n",
            "Epoch 486 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 487 | loss: 0.6815 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 488 | loss: 0.6814 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 489 | loss: 0.6816 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 490 | loss: 0.6817 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 491 | loss: 0.6815 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 492 | loss: 0.6816 | Validation score: 0.5483 | Test score: 0.5956\n",
            "Epoch 493 | loss: 0.6814 | Validation score: 0.5483 | Test score: 0.5956\n",
            "Epoch 494 | loss: 0.6817 | Validation score: 0.5483 | Test score: 0.5956\n",
            "Epoch 495 | loss: 0.6814 | Validation score: 0.5483 | Test score: 0.5956\n",
            "Epoch 496 | loss: 0.6816 | Validation score: 0.5483 | Test score: 0.5956\n",
            "Epoch 497 | loss: 0.6820 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 498 | loss: 0.6818 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 499 | loss: 0.6816 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 500 | loss: 0.6814 | Validation score: 0.5483 | Test score: 0.5956\n",
            "Epoch 501 | loss: 0.6815 | Validation score: 0.5483 | Test score: 0.5956\n",
            "Epoch 502 | loss: 0.6815 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 503 | loss: 0.6818 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 504 | loss: 0.6817 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 505 | loss: 0.6818 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 506 | loss: 0.6814 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 507 | loss: 0.6814 | Validation score: 0.5483 | Test score: 0.5952\n",
            "Epoch 508 | loss: 0.6814 | Validation score: 0.5481 | Test score: 0.5956\n",
            "Epoch 509 | loss: 0.6816 | Validation score: 0.5481 | Test score: 0.5952\n",
            "Epoch 510 | loss: 0.6814 | Validation score: 0.5481 | Test score: 0.5952\n",
            "Epoch 511 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5952\n",
            "Epoch 512 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5952\n",
            "Epoch 513 | loss: 0.6816 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 514 | loss: 0.6816 | Validation score: 0.5474 | Test score: 0.5952\n",
            "Epoch 515 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5948\n",
            "Epoch 516 | loss: 0.6816 | Validation score: 0.5474 | Test score: 0.5948\n",
            "Epoch 517 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5948\n",
            "Epoch 518 | loss: 0.6818 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 519 | loss: 0.6818 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 520 | loss: 0.6815 | Validation score: 0.5470 | Test score: 0.5948\n",
            "Epoch 521 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5948\n",
            "Epoch 522 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5944\n",
            "Epoch 523 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5948\n",
            "Epoch 524 | loss: 0.6813 | Validation score: 0.5467 | Test score: 0.5952\n",
            "Epoch 525 | loss: 0.6812 | Validation score: 0.5467 | Test score: 0.5952\n",
            "Epoch 526 | loss: 0.6815 | Validation score: 0.5467 | Test score: 0.5952\n",
            "Epoch 527 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 528 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 529 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 530 | loss: 0.6813 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 531 | loss: 0.6817 | Validation score: 0.5470 | Test score: 0.5956\n",
            "Epoch 532 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 533 | loss: 0.6818 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 534 | loss: 0.6813 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 535 | loss: 0.6815 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 536 | loss: 0.6818 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 537 | loss: 0.6816 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 538 | loss: 0.6819 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 539 | loss: 0.6816 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 540 | loss: 0.6813 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 541 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5952\n",
            "Epoch 542 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 543 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5952\n",
            "Epoch 544 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5956\n",
            "Epoch 545 | loss: 0.6816 | Validation score: 0.5467 | Test score: 0.5956\n",
            "Epoch 546 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 547 | loss: 0.6817 | Validation score: 0.5474 | Test score: 0.5956\n",
            "Epoch 548 | loss: 0.6820 | Validation score: 0.5470 | Test score: 0.5960\n",
            "Epoch 549 | loss: 0.6815 | Validation score: 0.5470 | Test score: 0.5956\n",
            "Epoch 550 | loss: 0.6813 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 551 | loss: 0.6811 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 552 | loss: 0.6815 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 553 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5956\n",
            "Epoch 554 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5956\n",
            "Epoch 555 | loss: 0.6817 | Validation score: 0.5474 | Test score: 0.5956\n",
            "Epoch 556 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5956\n",
            "Epoch 557 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5956\n",
            "Epoch 558 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5956\n",
            "Epoch 559 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 560 | loss: 0.6816 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 561 | loss: 0.6818 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 562 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 563 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 564 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 565 | loss: 0.6810 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 566 | loss: 0.6815 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 567 | loss: 0.6815 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 568 | loss: 0.6816 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 569 | loss: 0.6816 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 570 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 571 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 572 | loss: 0.6813 | Validation score: 0.5472 | Test score: 0.5968\n",
            "Epoch 573 | loss: 0.6818 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 574 | loss: 0.6813 | Validation score: 0.5472 | Test score: 0.5968\n",
            "Epoch 575 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 576 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 577 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 578 | loss: 0.6815 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 579 | loss: 0.6815 | Validation score: 0.5472 | Test score: 0.5964\n",
            "Epoch 580 | loss: 0.6817 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 581 | loss: 0.6816 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 582 | loss: 0.6815 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 583 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 584 | loss: 0.6808 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 585 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 586 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 587 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 588 | loss: 0.6813 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 589 | loss: 0.6815 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 590 | loss: 0.6812 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 591 | loss: 0.6811 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 592 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 593 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 594 | loss: 0.6812 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 595 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 596 | loss: 0.6815 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 597 | loss: 0.6815 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 598 | loss: 0.6815 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 599 | loss: 0.6816 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 600 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 601 | loss: 0.6819 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 602 | loss: 0.6813 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 603 | loss: 0.6811 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 604 | loss: 0.6810 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 605 | loss: 0.6812 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 606 | loss: 0.6811 | Validation score: 0.5470 | Test score: 0.5968\n",
            "Epoch 607 | loss: 0.6816 | Validation score: 0.5472 | Test score: 0.5968\n",
            "Epoch 608 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 609 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5968\n",
            "Epoch 610 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5964\n",
            "Epoch 611 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5964\n",
            "Epoch 612 | loss: 0.6815 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 613 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5964\n",
            "Epoch 614 | loss: 0.6815 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 615 | loss: 0.6815 | Validation score: 0.5481 | Test score: 0.5964\n",
            "Epoch 616 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 617 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5964\n",
            "Epoch 618 | loss: 0.6817 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 619 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 620 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 621 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 622 | loss: 0.6817 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 623 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 624 | loss: 0.6815 | Validation score: 0.5477 | Test score: 0.5972\n",
            "Epoch 625 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5976\n",
            "Epoch 626 | loss: 0.6815 | Validation score: 0.5474 | Test score: 0.5976\n",
            "Epoch 627 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 628 | loss: 0.6817 | Validation score: 0.5472 | Test score: 0.5976\n",
            "Epoch 629 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5976\n",
            "Epoch 630 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5976\n",
            "Epoch 631 | loss: 0.6813 | Validation score: 0.5470 | Test score: 0.5976\n",
            "Epoch 632 | loss: 0.6813 | Validation score: 0.5470 | Test score: 0.5980\n",
            "Epoch 633 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5980\n",
            "Epoch 634 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 635 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 636 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 637 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 638 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 639 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 640 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 641 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 642 | loss: 0.6817 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 643 | loss: 0.6817 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 644 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 645 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 646 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 647 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 648 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 649 | loss: 0.6808 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 650 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 651 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 652 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 653 | loss: 0.6820 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 654 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 655 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 656 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 657 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 658 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 659 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 660 | loss: 0.6812 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 661 | loss: 0.6816 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 662 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 663 | loss: 0.6814 | Validation score: 0.5483 | Test score: 0.5980\n",
            "Epoch 664 | loss: 0.6815 | Validation score: 0.5483 | Test score: 0.5980\n",
            "Epoch 665 | loss: 0.6811 | Validation score: 0.5483 | Test score: 0.5980\n",
            "Epoch 666 | loss: 0.6813 | Validation score: 0.5483 | Test score: 0.5980\n",
            "Epoch 667 | loss: 0.6812 | Validation score: 0.5483 | Test score: 0.5980\n",
            "Epoch 668 | loss: 0.6811 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 669 | loss: 0.6815 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 670 | loss: 0.6811 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 671 | loss: 0.6817 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 672 | loss: 0.6815 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 673 | loss: 0.6810 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 674 | loss: 0.6812 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 675 | loss: 0.6812 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 676 | loss: 0.6814 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 677 | loss: 0.6812 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 678 | loss: 0.6814 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 679 | loss: 0.6815 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 680 | loss: 0.6812 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 681 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 682 | loss: 0.6815 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 683 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 684 | loss: 0.6814 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 685 | loss: 0.6818 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 686 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 687 | loss: 0.6811 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 688 | loss: 0.6816 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 689 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 690 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 691 | loss: 0.6816 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 692 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 693 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 694 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 695 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 696 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 697 | loss: 0.6810 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 698 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 699 | loss: 0.6813 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 700 | loss: 0.6817 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 701 | loss: 0.6807 | Validation score: 0.5470 | Test score: 0.5980\n",
            "Epoch 702 | loss: 0.6813 | Validation score: 0.5470 | Test score: 0.5980\n",
            "Epoch 703 | loss: 0.6808 | Validation score: 0.5467 | Test score: 0.5980\n",
            "Epoch 704 | loss: 0.6811 | Validation score: 0.5467 | Test score: 0.5980\n",
            "Epoch 705 | loss: 0.6812 | Validation score: 0.5467 | Test score: 0.5980\n",
            "Epoch 706 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5980\n",
            "Epoch 707 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 708 | loss: 0.6811 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 709 | loss: 0.6811 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 710 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 711 | loss: 0.6810 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 712 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 713 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 714 | loss: 0.6809 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 715 | loss: 0.6816 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 716 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5980\n",
            "Epoch 717 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 718 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 719 | loss: 0.6814 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 720 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 721 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 722 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 723 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 724 | loss: 0.6807 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 725 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 726 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 727 | loss: 0.6811 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 728 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 729 | loss: 0.6811 | Validation score: 0.5481 | Test score: 0.5980\n",
            "Epoch 730 | loss: 0.6810 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 731 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 732 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 733 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 734 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 735 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 736 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 737 | loss: 0.6814 | Validation score: 0.5479 | Test score: 0.5980\n",
            "Epoch 738 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 739 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 740 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5980\n",
            "Epoch 741 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5984\n",
            "Epoch 742 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5984\n",
            "Epoch 743 | loss: 0.6816 | Validation score: 0.5474 | Test score: 0.5976\n",
            "Epoch 744 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 745 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 746 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 747 | loss: 0.6815 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 748 | loss: 0.6813 | Validation score: 0.5472 | Test score: 0.5980\n",
            "Epoch 749 | loss: 0.6813 | Validation score: 0.5472 | Test score: 0.5976\n",
            "Epoch 750 | loss: 0.6812 | Validation score: 0.5467 | Test score: 0.5976\n",
            "Epoch 751 | loss: 0.6812 | Validation score: 0.5467 | Test score: 0.5976\n",
            "Epoch 752 | loss: 0.6817 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 753 | loss: 0.6811 | Validation score: 0.5467 | Test score: 0.5976\n",
            "Epoch 754 | loss: 0.6814 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 755 | loss: 0.6810 | Validation score: 0.5467 | Test score: 0.5972\n",
            "Epoch 756 | loss: 0.6810 | Validation score: 0.5467 | Test score: 0.5968\n",
            "Epoch 757 | loss: 0.6811 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 758 | loss: 0.6809 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 759 | loss: 0.6808 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 760 | loss: 0.6808 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 761 | loss: 0.6814 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 762 | loss: 0.6812 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 763 | loss: 0.6811 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 764 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 765 | loss: 0.6809 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 766 | loss: 0.6812 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 767 | loss: 0.6811 | Validation score: 0.5470 | Test score: 0.5972\n",
            "Epoch 768 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 769 | loss: 0.6816 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 770 | loss: 0.6811 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 771 | loss: 0.6814 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 772 | loss: 0.6812 | Validation score: 0.5472 | Test score: 0.5972\n",
            "Epoch 773 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 774 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 775 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 776 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 777 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 778 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 779 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 780 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5972\n",
            "Epoch 781 | loss: 0.6809 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 782 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 783 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 784 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 785 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 786 | loss: 0.6809 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 787 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 788 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 789 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 790 | loss: 0.6808 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 791 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 792 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 793 | loss: 0.6810 | Validation score: 0.5479 | Test score: 0.5968\n",
            "Epoch 794 | loss: 0.6815 | Validation score: 0.5479 | Test score: 0.5968\n",
            "Epoch 795 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5968\n",
            "Epoch 796 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 797 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 798 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 799 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 800 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 801 | loss: 0.6808 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 802 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 803 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 804 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 805 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 806 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 807 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5972\n",
            "Epoch 808 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5972\n",
            "Epoch 809 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5972\n",
            "Epoch 810 | loss: 0.6809 | Validation score: 0.5477 | Test score: 0.5972\n",
            "Epoch 811 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5972\n",
            "Epoch 812 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5972\n",
            "Epoch 813 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5972\n",
            "Epoch 814 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5972\n",
            "Epoch 815 | loss: 0.6808 | Validation score: 0.5479 | Test score: 0.5968\n",
            "Epoch 816 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 817 | loss: 0.6809 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 818 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 819 | loss: 0.6806 | Validation score: 0.5477 | Test score: 0.5964\n",
            "Epoch 820 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5964\n",
            "Epoch 821 | loss: 0.6808 | Validation score: 0.5477 | Test score: 0.5964\n",
            "Epoch 822 | loss: 0.6807 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 823 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 824 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 825 | loss: 0.6807 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 826 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 827 | loss: 0.6810 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 828 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 829 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 830 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 831 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 832 | loss: 0.6807 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 833 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 834 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 835 | loss: 0.6810 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 836 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 837 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 838 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 839 | loss: 0.6809 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 840 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 841 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 842 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 843 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 844 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 845 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 846 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 847 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 848 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 849 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 850 | loss: 0.6808 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 851 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 852 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 853 | loss: 0.6814 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 854 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 855 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 856 | loss: 0.6810 | Validation score: 0.5479 | Test score: 0.5956\n",
            "Epoch 857 | loss: 0.6809 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 858 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5960\n",
            "Epoch 859 | loss: 0.6812 | Validation score: 0.5477 | Test score: 0.5960\n",
            "Epoch 860 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5960\n",
            "Epoch 861 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 862 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 863 | loss: 0.6814 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 864 | loss: 0.6814 | Validation score: 0.5477 | Test score: 0.5960\n",
            "Epoch 865 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 866 | loss: 0.6810 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 867 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 868 | loss: 0.6807 | Validation score: 0.5477 | Test score: 0.5960\n",
            "Epoch 869 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 870 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 871 | loss: 0.6812 | Validation score: 0.5474 | Test score: 0.5960\n",
            "Epoch 872 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 873 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 874 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 875 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 876 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 877 | loss: 0.6805 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 878 | loss: 0.6811 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 879 | loss: 0.6810 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 880 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 881 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 882 | loss: 0.6809 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 883 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 884 | loss: 0.6813 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 885 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 886 | loss: 0.6808 | Validation score: 0.5474 | Test score: 0.5964\n",
            "Epoch 887 | loss: 0.6807 | Validation score: 0.5477 | Test score: 0.5964\n",
            "Epoch 888 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5968\n",
            "Epoch 889 | loss: 0.6806 | Validation score: 0.5479 | Test score: 0.5968\n",
            "Epoch 890 | loss: 0.6811 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 891 | loss: 0.6813 | Validation score: 0.5477 | Test score: 0.5968\n",
            "Epoch 892 | loss: 0.6808 | Validation score: 0.5479 | Test score: 0.5968\n",
            "Epoch 893 | loss: 0.6808 | Validation score: 0.5479 | Test score: 0.5968\n",
            "Epoch 894 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 895 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5960\n",
            "Epoch 896 | loss: 0.6810 | Validation score: 0.5479 | Test score: 0.5960\n",
            "Epoch 897 | loss: 0.6806 | Validation score: 0.5479 | Test score: 0.5960\n",
            "Epoch 898 | loss: 0.6810 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 899 | loss: 0.6812 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 900 | loss: 0.6814 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 901 | loss: 0.6807 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 902 | loss: 0.6807 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 903 | loss: 0.6806 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 904 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5964\n",
            "Epoch 905 | loss: 0.6808 | Validation score: 0.5477 | Test score: 0.5956\n",
            "Epoch 906 | loss: 0.6810 | Validation score: 0.5477 | Test score: 0.5960\n",
            "Epoch 907 | loss: 0.6813 | Validation score: 0.5479 | Test score: 0.5960\n",
            "Epoch 908 | loss: 0.6811 | Validation score: 0.5479 | Test score: 0.5960\n",
            "Epoch 909 | loss: 0.6809 | Validation score: 0.5479 | Test score: 0.5960\n",
            "Epoch 910 | loss: 0.6809 | Validation score: 0.5481 | Test score: 0.5960\n",
            "Epoch 911 | loss: 0.6807 | Validation score: 0.5481 | Test score: 0.5960\n",
            "Epoch 912 | loss: 0.6814 | Validation score: 0.5483 | Test score: 0.5960\n",
            "Epoch 913 | loss: 0.6811 | Validation score: 0.5483 | Test score: 0.5960\n",
            "Epoch 914 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5960\n",
            "Epoch 915 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5960\n",
            "Epoch 916 | loss: 0.6807 | Validation score: 0.5483 | Test score: 0.5960\n",
            "Epoch 917 | loss: 0.6807 | Validation score: 0.5483 | Test score: 0.5964\n",
            "Epoch 918 | loss: 0.6810 | Validation score: 0.5483 | Test score: 0.5964\n",
            "Epoch 919 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5964\n",
            "Epoch 920 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5964\n",
            "Epoch 921 | loss: 0.6811 | Validation score: 0.5481 | Test score: 0.5964\n",
            "Epoch 922 | loss: 0.6810 | Validation score: 0.5481 | Test score: 0.5964\n",
            "Epoch 923 | loss: 0.6807 | Validation score: 0.5481 | Test score: 0.5968\n",
            "Epoch 924 | loss: 0.6807 | Validation score: 0.5481 | Test score: 0.5968\n",
            "Epoch 925 | loss: 0.6809 | Validation score: 0.5481 | Test score: 0.5968\n",
            "Epoch 926 | loss: 0.6811 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 927 | loss: 0.6809 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 928 | loss: 0.6810 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 929 | loss: 0.6812 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 930 | loss: 0.6810 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 931 | loss: 0.6807 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 932 | loss: 0.6809 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 933 | loss: 0.6812 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 934 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 935 | loss: 0.6811 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 936 | loss: 0.6810 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 937 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 938 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 939 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 940 | loss: 0.6808 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 941 | loss: 0.6805 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 942 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 943 | loss: 0.6809 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 944 | loss: 0.6806 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 945 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 946 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 947 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5976\n",
            "Epoch 948 | loss: 0.6809 | Validation score: 0.5486 | Test score: 0.5976\n",
            "Epoch 949 | loss: 0.6811 | Validation score: 0.5486 | Test score: 0.5976\n",
            "Epoch 950 | loss: 0.6810 | Validation score: 0.5483 | Test score: 0.5976\n",
            "Epoch 951 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5976\n",
            "Epoch 952 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5976\n",
            "Epoch 953 | loss: 0.6809 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 954 | loss: 0.6807 | Validation score: 0.5488 | Test score: 0.5980\n",
            "Epoch 955 | loss: 0.6805 | Validation score: 0.5488 | Test score: 0.5976\n",
            "Epoch 956 | loss: 0.6812 | Validation score: 0.5488 | Test score: 0.5980\n",
            "Epoch 957 | loss: 0.6807 | Validation score: 0.5490 | Test score: 0.5980\n",
            "Epoch 958 | loss: 0.6807 | Validation score: 0.5490 | Test score: 0.5980\n",
            "Epoch 959 | loss: 0.6811 | Validation score: 0.5490 | Test score: 0.5980\n",
            "Epoch 960 | loss: 0.6810 | Validation score: 0.5490 | Test score: 0.5980\n",
            "Epoch 961 | loss: 0.6809 | Validation score: 0.5490 | Test score: 0.5980\n",
            "Epoch 962 | loss: 0.6810 | Validation score: 0.5490 | Test score: 0.5980\n",
            "Epoch 963 | loss: 0.6811 | Validation score: 0.5490 | Test score: 0.5980\n",
            "Epoch 964 | loss: 0.6809 | Validation score: 0.5492 | Test score: 0.5980\n",
            "Epoch 965 | loss: 0.6809 | Validation score: 0.5492 | Test score: 0.5980\n",
            "Epoch 966 | loss: 0.6809 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 967 | loss: 0.6809 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 968 | loss: 0.6809 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 969 | loss: 0.6812 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 970 | loss: 0.6812 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 971 | loss: 0.6807 | Validation score: 0.5492 | Test score: 0.5972\n",
            "Epoch 972 | loss: 0.6808 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 973 | loss: 0.6807 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 974 | loss: 0.6809 | Validation score: 0.5492 | Test score: 0.5972\n",
            "Epoch 975 | loss: 0.6811 | Validation score: 0.5492 | Test score: 0.5972\n",
            "Epoch 976 | loss: 0.6808 | Validation score: 0.5492 | Test score: 0.5972\n",
            "Epoch 977 | loss: 0.6804 | Validation score: 0.5492 | Test score: 0.5972\n",
            "Epoch 978 | loss: 0.6808 | Validation score: 0.5492 | Test score: 0.5972\n",
            "Epoch 979 | loss: 0.6810 | Validation score: 0.5492 | Test score: 0.5972\n",
            "Epoch 980 | loss: 0.6807 | Validation score: 0.5492 | Test score: 0.5968\n",
            "Epoch 981 | loss: 0.6810 | Validation score: 0.5490 | Test score: 0.5968\n",
            "Epoch 982 | loss: 0.6807 | Validation score: 0.5490 | Test score: 0.5968\n",
            "Epoch 983 | loss: 0.6810 | Validation score: 0.5490 | Test score: 0.5968\n",
            "Epoch 984 | loss: 0.6809 | Validation score: 0.5490 | Test score: 0.5968\n",
            "Epoch 985 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 986 | loss: 0.6805 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 987 | loss: 0.6809 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 988 | loss: 0.6808 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 989 | loss: 0.6805 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 990 | loss: 0.6809 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 991 | loss: 0.6812 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 992 | loss: 0.6809 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 993 | loss: 0.6808 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 994 | loss: 0.6808 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 995 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 996 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 997 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 998 | loss: 0.6811 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 999 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1000 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1001 | loss: 0.6809 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1002 | loss: 0.6806 | Validation score: 0.5488 | Test score: 0.5968\n",
            "Epoch 1003 | loss: 0.6806 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1004 | loss: 0.6810 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1005 | loss: 0.6804 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1006 | loss: 0.6810 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1007 | loss: 0.6808 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1008 | loss: 0.6810 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1009 | loss: 0.6809 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1010 | loss: 0.6811 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1011 | loss: 0.6807 | Validation score: 0.5492 | Test score: 0.5972\n",
            "Epoch 1012 | loss: 0.6806 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1013 | loss: 0.6813 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1014 | loss: 0.6809 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1015 | loss: 0.6810 | Validation score: 0.5490 | Test score: 0.5972\n",
            "Epoch 1016 | loss: 0.6811 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1017 | loss: 0.6813 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1018 | loss: 0.6808 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1019 | loss: 0.6807 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1020 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1021 | loss: 0.6808 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1022 | loss: 0.6808 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1023 | loss: 0.6806 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 1024 | loss: 0.6811 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1025 | loss: 0.6811 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 1026 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1027 | loss: 0.6806 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1028 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1029 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1030 | loss: 0.6806 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1031 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1032 | loss: 0.6811 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1033 | loss: 0.6806 | Validation score: 0.5483 | Test score: 0.5976\n",
            "Epoch 1034 | loss: 0.6805 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 1035 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1036 | loss: 0.6810 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1037 | loss: 0.6810 | Validation score: 0.5483 | Test score: 0.5972\n",
            "Epoch 1038 | loss: 0.6808 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1039 | loss: 0.6808 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1040 | loss: 0.6807 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1041 | loss: 0.6808 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1042 | loss: 0.6811 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1043 | loss: 0.6809 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1044 | loss: 0.6808 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1045 | loss: 0.6808 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1046 | loss: 0.6807 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1047 | loss: 0.6810 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1048 | loss: 0.6810 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1049 | loss: 0.6809 | Validation score: 0.5481 | Test score: 0.5976\n",
            "Epoch 1050 | loss: 0.6813 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1051 | loss: 0.6806 | Validation score: 0.5481 | Test score: 0.5972\n",
            "Epoch 1052 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 1053 | loss: 0.6805 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 1054 | loss: 0.6807 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1055 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1056 | loss: 0.6806 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1057 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5972\n",
            "Epoch 1058 | loss: 0.6810 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1059 | loss: 0.6813 | Validation score: 0.5488 | Test score: 0.5972\n",
            "Epoch 1060 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5976\n",
            "Epoch 1061 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1062 | loss: 0.6810 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1063 | loss: 0.6809 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1064 | loss: 0.6805 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1065 | loss: 0.6810 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1066 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1067 | loss: 0.6809 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1068 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1069 | loss: 0.6805 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1070 | loss: 0.6806 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1071 | loss: 0.6806 | Validation score: 0.5486 | Test score: 0.5980\n",
            "Epoch 1072 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1073 | loss: 0.6805 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1074 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1075 | loss: 0.6812 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1076 | loss: 0.6811 | Validation score: 0.5488 | Test score: 0.5984\n",
            "Epoch 1077 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1078 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1079 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1080 | loss: 0.6803 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1081 | loss: 0.6810 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1082 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1083 | loss: 0.6809 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1084 | loss: 0.6805 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1085 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1086 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1087 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1088 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1089 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1090 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1091 | loss: 0.6805 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1092 | loss: 0.6811 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1093 | loss: 0.6804 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1094 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1095 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1096 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1097 | loss: 0.6807 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1098 | loss: 0.6809 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1099 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1100 | loss: 0.6803 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1101 | loss: 0.6808 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1102 | loss: 0.6805 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1103 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1104 | loss: 0.6807 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1105 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1106 | loss: 0.6805 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1107 | loss: 0.6806 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1108 | loss: 0.6808 | Validation score: 0.5481 | Test score: 0.5984\n",
            "Epoch 1109 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1110 | loss: 0.6810 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1111 | loss: 0.6807 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1112 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1113 | loss: 0.6805 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1114 | loss: 0.6805 | Validation score: 0.5481 | Test score: 0.5984\n",
            "Epoch 1115 | loss: 0.6807 | Validation score: 0.5481 | Test score: 0.5984\n",
            "Epoch 1116 | loss: 0.6803 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1117 | loss: 0.6810 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1118 | loss: 0.6805 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1119 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1120 | loss: 0.6808 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1121 | loss: 0.6806 | Validation score: 0.5483 | Test score: 0.5984\n",
            "Epoch 1122 | loss: 0.6806 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1123 | loss: 0.6807 | Validation score: 0.5486 | Test score: 0.5984\n",
            "Epoch 1124 | loss: 0.6807 | Validation score: 0.5488 | Test score: 0.5984\n",
            "Epoch 1125 | loss: 0.6804 | Validation score: 0.5488 | Test score: 0.5984\n",
            "Epoch 1126 | loss: 0.6809 | Validation score: 0.5488 | Test score: 0.5984\n",
            "Epoch 1127 | loss: 0.6804 | Validation score: 0.5492 | Test score: 0.5984\n",
            "Epoch 1128 | loss: 0.6807 | Validation score: 0.5490 | Test score: 0.5984\n",
            "Epoch 1129 | loss: 0.6806 | Validation score: 0.5490 | Test score: 0.5984\n",
            "Epoch 1130 | loss: 0.6804 | Validation score: 0.5492 | Test score: 0.5984\n",
            "Epoch 1131 | loss: 0.6807 | Validation score: 0.5495 | Test score: 0.5984\n",
            "Epoch 1132 | loss: 0.6806 | Validation score: 0.5495 | Test score: 0.5984\n",
            "Epoch 1133 | loss: 0.6803 | Validation score: 0.5492 | Test score: 0.5980\n",
            "Epoch 1134 | loss: 0.6807 | Validation score: 0.5492 | Test score: 0.5980\n",
            "Epoch 1135 | loss: 0.6807 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1136 | loss: 0.6808 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1137 | loss: 0.6806 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1138 | loss: 0.6803 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1139 | loss: 0.6806 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1140 | loss: 0.6809 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1141 | loss: 0.6809 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1142 | loss: 0.6807 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1143 | loss: 0.6805 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1144 | loss: 0.6805 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1145 | loss: 0.6807 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1146 | loss: 0.6806 | Validation score: 0.5492 | Test score: 0.5976\n",
            "Epoch 1147 | loss: 0.6804 | Validation score: 0.5495 | Test score: 0.5976\n",
            "Epoch 1148 | loss: 0.6802 | Validation score: 0.5495 | Test score: 0.5976\n",
            "Epoch 1149 | loss: 0.6809 | Validation score: 0.5495 | Test score: 0.5976\n",
            "Epoch 1150 | loss: 0.6807 | Validation score: 0.5497 | Test score: 0.5976\n",
            "Epoch 1151 | loss: 0.6807 | Validation score: 0.5495 | Test score: 0.5976\n",
            "Epoch 1152 | loss: 0.6806 | Validation score: 0.5497 | Test score: 0.5976\n",
            "Epoch 1153 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5976\n",
            "Epoch 1154 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5976\n",
            "Epoch 1155 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5976\n",
            "Epoch 1156 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5972\n",
            "Epoch 1157 | loss: 0.6808 | Validation score: 0.5499 | Test score: 0.5972\n",
            "Epoch 1158 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5972\n",
            "Epoch 1159 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5972\n",
            "Epoch 1160 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5972\n",
            "Epoch 1161 | loss: 0.6805 | Validation score: 0.5502 | Test score: 0.5972\n",
            "Epoch 1162 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5972\n",
            "Epoch 1163 | loss: 0.6810 | Validation score: 0.5502 | Test score: 0.5972\n",
            "Epoch 1164 | loss: 0.6807 | Validation score: 0.5502 | Test score: 0.5972\n",
            "Epoch 1165 | loss: 0.6809 | Validation score: 0.5502 | Test score: 0.5972\n",
            "Epoch 1166 | loss: 0.6810 | Validation score: 0.5502 | Test score: 0.5972\n",
            "Epoch 1167 | loss: 0.6806 | Validation score: 0.5502 | Test score: 0.5972\n",
            "Epoch 1168 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5972\n",
            "Epoch 1169 | loss: 0.6809 | Validation score: 0.5499 | Test score: 0.5972\n",
            "Epoch 1170 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5972\n",
            "Epoch 1171 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1172 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1173 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1174 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1175 | loss: 0.6810 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1176 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1177 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1178 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1179 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1180 | loss: 0.6807 | Validation score: 0.5497 | Test score: 0.5968\n",
            "Epoch 1181 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5968\n",
            "Epoch 1182 | loss: 0.6808 | Validation score: 0.5497 | Test score: 0.5968\n",
            "Epoch 1183 | loss: 0.6805 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1184 | loss: 0.6811 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1185 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1186 | loss: 0.6806 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1187 | loss: 0.6804 | Validation score: 0.5495 | Test score: 0.5964\n",
            "Epoch 1188 | loss: 0.6808 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1189 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1190 | loss: 0.6811 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1191 | loss: 0.6805 | Validation score: 0.5495 | Test score: 0.5964\n",
            "Epoch 1192 | loss: 0.6808 | Validation score: 0.5495 | Test score: 0.5964\n",
            "Epoch 1193 | loss: 0.6806 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1194 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1195 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1196 | loss: 0.6808 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1197 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1198 | loss: 0.6810 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1199 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1200 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1201 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1202 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1203 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1204 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1205 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1206 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1207 | loss: 0.6810 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1208 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1209 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1210 | loss: 0.6809 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1211 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1212 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1213 | loss: 0.6809 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1214 | loss: 0.6807 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1215 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1216 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1217 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1218 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1219 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1220 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1221 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1222 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1223 | loss: 0.6808 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1224 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1225 | loss: 0.6808 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1226 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1227 | loss: 0.6807 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1228 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1229 | loss: 0.6805 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1230 | loss: 0.6806 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1231 | loss: 0.6805 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1232 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1233 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1234 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1235 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1236 | loss: 0.6808 | Validation score: 0.5495 | Test score: 0.5960\n",
            "Epoch 1237 | loss: 0.6808 | Validation score: 0.5495 | Test score: 0.5960\n",
            "Epoch 1238 | loss: 0.6808 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1239 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1240 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1241 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1242 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1243 | loss: 0.6809 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1244 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1245 | loss: 0.6810 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1246 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1247 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1248 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1249 | loss: 0.6807 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1250 | loss: 0.6806 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1251 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1252 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1253 | loss: 0.6807 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1254 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1255 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1256 | loss: 0.6807 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1257 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1258 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1259 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1260 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1261 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1262 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1263 | loss: 0.6809 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1264 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1265 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1266 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1267 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1268 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1269 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1270 | loss: 0.6810 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1271 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1272 | loss: 0.6807 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1273 | loss: 0.6808 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1274 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1275 | loss: 0.6806 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1276 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1277 | loss: 0.6801 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1278 | loss: 0.6808 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1279 | loss: 0.6807 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1280 | loss: 0.6808 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1281 | loss: 0.6809 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1282 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1283 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1284 | loss: 0.6800 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1285 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1286 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1287 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1288 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1289 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1290 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1291 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1292 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1293 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1294 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1295 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1296 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1297 | loss: 0.6809 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1298 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1299 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1300 | loss: 0.6808 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1301 | loss: 0.6807 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1302 | loss: 0.6802 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1303 | loss: 0.6807 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1304 | loss: 0.6804 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1305 | loss: 0.6802 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1306 | loss: 0.6807 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1307 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1308 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1309 | loss: 0.6809 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1310 | loss: 0.6808 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1311 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1312 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1313 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1314 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1315 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1316 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1317 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1318 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1319 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1320 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1321 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1322 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1323 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1324 | loss: 0.6809 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1325 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1326 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1327 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1328 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1329 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1330 | loss: 0.6798 | Validation score: 0.5506 | Test score: 0.5956\n",
            "Epoch 1331 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1332 | loss: 0.6802 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1333 | loss: 0.6807 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1334 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1335 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1336 | loss: 0.6807 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1337 | loss: 0.6809 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1338 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5956\n",
            "Epoch 1339 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5956\n",
            "Epoch 1340 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1341 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1342 | loss: 0.6807 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1343 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5956\n",
            "Epoch 1344 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5956\n",
            "Epoch 1345 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1346 | loss: 0.6806 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1347 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1348 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1349 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1350 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1351 | loss: 0.6808 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1352 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1353 | loss: 0.6803 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1354 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1355 | loss: 0.6801 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1356 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1357 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1358 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1359 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5968\n",
            "Epoch 1360 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5968\n",
            "Epoch 1361 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5968\n",
            "Epoch 1362 | loss: 0.6802 | Validation score: 0.5506 | Test score: 0.5968\n",
            "Epoch 1363 | loss: 0.6808 | Validation score: 0.5506 | Test score: 0.5968\n",
            "Epoch 1364 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5968\n",
            "Epoch 1365 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5968\n",
            "Epoch 1366 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5968\n",
            "Epoch 1367 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5968\n",
            "Epoch 1368 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5968\n",
            "Epoch 1369 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1370 | loss: 0.6803 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1371 | loss: 0.6802 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1372 | loss: 0.6804 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1373 | loss: 0.6801 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1374 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1375 | loss: 0.6802 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1376 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1377 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1378 | loss: 0.6806 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1379 | loss: 0.6808 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1380 | loss: 0.6806 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1381 | loss: 0.6803 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1382 | loss: 0.6808 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1383 | loss: 0.6803 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1384 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1385 | loss: 0.6807 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1386 | loss: 0.6800 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1387 | loss: 0.6803 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1388 | loss: 0.6804 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1389 | loss: 0.6802 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1390 | loss: 0.6804 | Validation score: 0.5508 | Test score: 0.5968\n",
            "Epoch 1391 | loss: 0.6803 | Validation score: 0.5508 | Test score: 0.5968\n",
            "Epoch 1392 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5968\n",
            "Epoch 1393 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5968\n",
            "Epoch 1394 | loss: 0.6806 | Validation score: 0.5502 | Test score: 0.5972\n",
            "Epoch 1395 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5968\n",
            "Epoch 1396 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5968\n",
            "Epoch 1397 | loss: 0.6807 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1398 | loss: 0.6807 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1399 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1400 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5968\n",
            "Epoch 1401 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5968\n",
            "Epoch 1402 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1403 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5968\n",
            "Epoch 1404 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1405 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1406 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1407 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1408 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1409 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1410 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1411 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1412 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1413 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1414 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1415 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1416 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1417 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1418 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1419 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1420 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1421 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1422 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1423 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1424 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1425 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1426 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1427 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1428 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1429 | loss: 0.6802 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1430 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1431 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1432 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1433 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1434 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1435 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1436 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1437 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1438 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1439 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1440 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1441 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1442 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1443 | loss: 0.6806 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1444 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1445 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1446 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1447 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1448 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1449 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1450 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1451 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1452 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1453 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1454 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1455 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1456 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1457 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1458 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1459 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1460 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1461 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1462 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1463 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1464 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1465 | loss: 0.6806 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1466 | loss: 0.6808 | Validation score: 0.5502 | Test score: 0.5968\n",
            "Epoch 1467 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5968\n",
            "Epoch 1468 | loss: 0.6807 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1469 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1470 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1471 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1472 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5968\n",
            "Epoch 1473 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5968\n",
            "Epoch 1474 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1475 | loss: 0.6807 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1476 | loss: 0.6802 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1477 | loss: 0.6805 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1478 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1479 | loss: 0.6807 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1480 | loss: 0.6803 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1481 | loss: 0.6802 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1482 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1483 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1484 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1485 | loss: 0.6803 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1486 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1487 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1488 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1489 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1490 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1491 | loss: 0.6808 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1492 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1493 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1494 | loss: 0.6799 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1495 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1496 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1497 | loss: 0.6800 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1498 | loss: 0.6805 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1499 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1500 | loss: 0.6802 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1501 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1502 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1503 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5964\n",
            "Epoch 1504 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1505 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1506 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1507 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1508 | loss: 0.6800 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1509 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1510 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1511 | loss: 0.6799 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1512 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1513 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1514 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1515 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1516 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1517 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1518 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1519 | loss: 0.6800 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1520 | loss: 0.6805 | Validation score: 0.5511 | Test score: 0.5964\n",
            "Epoch 1521 | loss: 0.6805 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1522 | loss: 0.6799 | Validation score: 0.5508 | Test score: 0.5964\n",
            "Epoch 1523 | loss: 0.6803 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1524 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1525 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1526 | loss: 0.6806 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1527 | loss: 0.6801 | Validation score: 0.5506 | Test score: 0.5964\n",
            "Epoch 1528 | loss: 0.6804 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1529 | loss: 0.6807 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1530 | loss: 0.6803 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1531 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1532 | loss: 0.6805 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1533 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1534 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1535 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1536 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1537 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1538 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1539 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1540 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1541 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1542 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1543 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1544 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1545 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1546 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1547 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1548 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1549 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1550 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1551 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1552 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1553 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1554 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1555 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1556 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1557 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1558 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1559 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1560 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1561 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1562 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1563 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1564 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1565 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1566 | loss: 0.6798 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1567 | loss: 0.6802 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1568 | loss: 0.6803 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1569 | loss: 0.6798 | Validation score: 0.5495 | Test score: 0.5960\n",
            "Epoch 1570 | loss: 0.6805 | Validation score: 0.5495 | Test score: 0.5960\n",
            "Epoch 1571 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1572 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1573 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1574 | loss: 0.6806 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1575 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1576 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1577 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1578 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1579 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1580 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1581 | loss: 0.6802 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1582 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1583 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1584 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1585 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1586 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5948\n",
            "Epoch 1587 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5948\n",
            "Epoch 1588 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5948\n",
            "Epoch 1589 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1590 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1591 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1592 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5948\n",
            "Epoch 1593 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1594 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1595 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1596 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1597 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1598 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1599 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1600 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5952\n",
            "Epoch 1601 | loss: 0.6802 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1602 | loss: 0.6802 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1603 | loss: 0.6803 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1604 | loss: 0.6801 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1605 | loss: 0.6801 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1606 | loss: 0.6804 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1607 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1608 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1609 | loss: 0.6802 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1610 | loss: 0.6802 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1611 | loss: 0.6803 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1612 | loss: 0.6801 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1613 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1614 | loss: 0.6803 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1615 | loss: 0.6802 | Validation score: 0.5495 | Test score: 0.5952\n",
            "Epoch 1616 | loss: 0.6805 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1617 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5952\n",
            "Epoch 1618 | loss: 0.6802 | Validation score: 0.5497 | Test score: 0.5948\n",
            "Epoch 1619 | loss: 0.6798 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1620 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1621 | loss: 0.6802 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1622 | loss: 0.6800 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1623 | loss: 0.6803 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1624 | loss: 0.6803 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1625 | loss: 0.6802 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1626 | loss: 0.6802 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1627 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1628 | loss: 0.6800 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1629 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1630 | loss: 0.6799 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1631 | loss: 0.6804 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1632 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1633 | loss: 0.6798 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1634 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1635 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1636 | loss: 0.6804 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1637 | loss: 0.6803 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1638 | loss: 0.6798 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1639 | loss: 0.6806 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1640 | loss: 0.6802 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1641 | loss: 0.6800 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1642 | loss: 0.6802 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1643 | loss: 0.6799 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1644 | loss: 0.6799 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1645 | loss: 0.6800 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1646 | loss: 0.6802 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1647 | loss: 0.6803 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1648 | loss: 0.6800 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1649 | loss: 0.6800 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1650 | loss: 0.6804 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1651 | loss: 0.6800 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1652 | loss: 0.6802 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1653 | loss: 0.6801 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1654 | loss: 0.6799 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1655 | loss: 0.6802 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1656 | loss: 0.6799 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1657 | loss: 0.6799 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1658 | loss: 0.6803 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1659 | loss: 0.6800 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1660 | loss: 0.6802 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1661 | loss: 0.6802 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1662 | loss: 0.6802 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1663 | loss: 0.6805 | Validation score: 0.5490 | Test score: 0.5948\n",
            "Epoch 1664 | loss: 0.6801 | Validation score: 0.5488 | Test score: 0.5948\n",
            "Epoch 1665 | loss: 0.6799 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1666 | loss: 0.6800 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1667 | loss: 0.6805 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1668 | loss: 0.6800 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1669 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5948\n",
            "Epoch 1670 | loss: 0.6798 | Validation score: 0.5492 | Test score: 0.5952\n",
            "Epoch 1671 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5952\n",
            "Epoch 1672 | loss: 0.6798 | Validation score: 0.5492 | Test score: 0.5952\n",
            "Epoch 1673 | loss: 0.6801 | Validation score: 0.5492 | Test score: 0.5952\n",
            "Epoch 1674 | loss: 0.6802 | Validation score: 0.5492 | Test score: 0.5952\n",
            "Epoch 1675 | loss: 0.6802 | Validation score: 0.5492 | Test score: 0.5952\n",
            "Epoch 1676 | loss: 0.6802 | Validation score: 0.5490 | Test score: 0.5952\n",
            "Epoch 1677 | loss: 0.6800 | Validation score: 0.5488 | Test score: 0.5952\n",
            "Epoch 1678 | loss: 0.6798 | Validation score: 0.5490 | Test score: 0.5952\n",
            "Epoch 1679 | loss: 0.6799 | Validation score: 0.5488 | Test score: 0.5952\n",
            "Epoch 1680 | loss: 0.6803 | Validation score: 0.5488 | Test score: 0.5952\n",
            "Epoch 1681 | loss: 0.6803 | Validation score: 0.5488 | Test score: 0.5952\n",
            "Epoch 1682 | loss: 0.6803 | Validation score: 0.5488 | Test score: 0.5952\n",
            "Epoch 1683 | loss: 0.6800 | Validation score: 0.5488 | Test score: 0.5952\n",
            "Epoch 1684 | loss: 0.6801 | Validation score: 0.5488 | Test score: 0.5952\n",
            "Epoch 1685 | loss: 0.6800 | Validation score: 0.5488 | Test score: 0.5952\n",
            "Epoch 1686 | loss: 0.6802 | Validation score: 0.5490 | Test score: 0.5952\n",
            "Epoch 1687 | loss: 0.6798 | Validation score: 0.5490 | Test score: 0.5956\n",
            "Epoch 1688 | loss: 0.6799 | Validation score: 0.5490 | Test score: 0.5956\n",
            "Epoch 1689 | loss: 0.6802 | Validation score: 0.5490 | Test score: 0.5956\n",
            "Epoch 1690 | loss: 0.6802 | Validation score: 0.5492 | Test score: 0.5956\n",
            "Epoch 1691 | loss: 0.6798 | Validation score: 0.5490 | Test score: 0.5956\n",
            "Epoch 1692 | loss: 0.6798 | Validation score: 0.5490 | Test score: 0.5956\n",
            "Epoch 1693 | loss: 0.6801 | Validation score: 0.5495 | Test score: 0.5956\n",
            "Epoch 1694 | loss: 0.6799 | Validation score: 0.5495 | Test score: 0.5956\n",
            "Epoch 1695 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1696 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1697 | loss: 0.6801 | Validation score: 0.5495 | Test score: 0.5956\n",
            "Epoch 1698 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1699 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1700 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1701 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1702 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1703 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1704 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1705 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1706 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1707 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1708 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1709 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1710 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1711 | loss: 0.6803 | Validation score: 0.5495 | Test score: 0.5956\n",
            "Epoch 1712 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1713 | loss: 0.6796 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1714 | loss: 0.6805 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1715 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1716 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1717 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1718 | loss: 0.6801 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1719 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1720 | loss: 0.6804 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1721 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5956\n",
            "Epoch 1722 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1723 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1724 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1725 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1726 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1727 | loss: 0.6795 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1728 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1729 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1730 | loss: 0.6804 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1731 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1732 | loss: 0.6802 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1733 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1734 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1735 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1736 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1737 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1738 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1739 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1740 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1741 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1742 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1743 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1744 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1745 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1746 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1747 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1748 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1749 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1750 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1751 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1752 | loss: 0.6798 | Validation score: 0.5497 | Test score: 0.5964\n",
            "Epoch 1753 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1754 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1755 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1756 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1757 | loss: 0.6797 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1758 | loss: 0.6803 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1759 | loss: 0.6805 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1760 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1761 | loss: 0.6800 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1762 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1763 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1764 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1765 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1766 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1767 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1768 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1769 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1770 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1771 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5964\n",
            "Epoch 1772 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1773 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1774 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1775 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1776 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1777 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5964\n",
            "Epoch 1778 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1779 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1780 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1781 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1782 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1783 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1784 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1785 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1786 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1787 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1788 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1789 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1790 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1791 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1792 | loss: 0.6801 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1793 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1794 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1795 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1796 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1797 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1798 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1799 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1800 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1801 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1802 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1803 | loss: 0.6793 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1804 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1805 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1806 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1807 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1808 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1809 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1810 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1811 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1812 | loss: 0.6797 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1813 | loss: 0.6806 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1814 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1815 | loss: 0.6799 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1816 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1817 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1818 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1819 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1820 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1821 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1822 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1823 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1824 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1825 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1826 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1827 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1828 | loss: 0.6802 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1829 | loss: 0.6802 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1830 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1831 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1832 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1833 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1834 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1835 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1836 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1837 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1838 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1839 | loss: 0.6799 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1840 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1841 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1842 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1843 | loss: 0.6801 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1844 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1845 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1846 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1847 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1848 | loss: 0.6804 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1849 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1850 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1851 | loss: 0.6797 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1852 | loss: 0.6805 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1853 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1854 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1855 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1856 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1857 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1858 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1859 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1860 | loss: 0.6796 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1861 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1862 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1863 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1864 | loss: 0.6803 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1865 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1866 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1867 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1868 | loss: 0.6796 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1869 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1870 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1871 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1872 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1873 | loss: 0.6795 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1874 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1875 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1876 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1877 | loss: 0.6796 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1878 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1879 | loss: 0.6797 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1880 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1881 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1882 | loss: 0.6796 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1883 | loss: 0.6796 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1884 | loss: 0.6804 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1885 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1886 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1887 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1888 | loss: 0.6795 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1889 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1890 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1891 | loss: 0.6802 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1892 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1893 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1894 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1895 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1896 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1897 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1898 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1899 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1900 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1901 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1902 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1903 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1904 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1905 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1906 | loss: 0.6803 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1907 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1908 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1909 | loss: 0.6797 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1910 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1911 | loss: 0.6799 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1912 | loss: 0.6796 | Validation score: 0.5497 | Test score: 0.5960\n",
            "Epoch 1913 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1914 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1915 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1916 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1917 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1918 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1919 | loss: 0.6802 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1920 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1921 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1922 | loss: 0.6795 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1923 | loss: 0.6797 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1924 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5960\n",
            "Epoch 1925 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1926 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1927 | loss: 0.6796 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1928 | loss: 0.6798 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1929 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1930 | loss: 0.6800 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1931 | loss: 0.6799 | Validation score: 0.5499 | Test score: 0.5956\n",
            "Epoch 1932 | loss: 0.6796 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1933 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1934 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1935 | loss: 0.6796 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1936 | loss: 0.6799 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1937 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1938 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1939 | loss: 0.6801 | Validation score: 0.5502 | Test score: 0.5956\n",
            "Epoch 1940 | loss: 0.6800 | Validation score: 0.5504 | Test score: 0.5956\n",
            "Epoch 1941 | loss: 0.6800 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1942 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1943 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1944 | loss: 0.6798 | Validation score: 0.5502 | Test score: 0.5960\n",
            "Epoch 1945 | loss: 0.6796 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1946 | loss: 0.6799 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1947 | loss: 0.6802 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1948 | loss: 0.6798 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1949 | loss: 0.6796 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1950 | loss: 0.6798 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1951 | loss: 0.6796 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1952 | loss: 0.6798 | Validation score: 0.5504 | Test score: 0.5960\n",
            "Epoch 1953 | loss: 0.6799 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1954 | loss: 0.6797 | Validation score: 0.5506 | Test score: 0.5960\n",
            "Epoch 1955 | loss: 0.6796 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1956 | loss: 0.6802 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1957 | loss: 0.6798 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1958 | loss: 0.6798 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1959 | loss: 0.6799 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1960 | loss: 0.6795 | Validation score: 0.5508 | Test score: 0.5960\n",
            "Epoch 1961 | loss: 0.6801 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1962 | loss: 0.6799 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1963 | loss: 0.6798 | Validation score: 0.5513 | Test score: 0.5956\n",
            "Epoch 1964 | loss: 0.6795 | Validation score: 0.5513 | Test score: 0.5956\n",
            "Epoch 1965 | loss: 0.6797 | Validation score: 0.5513 | Test score: 0.5956\n",
            "Epoch 1966 | loss: 0.6802 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1967 | loss: 0.6800 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1968 | loss: 0.6799 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1969 | loss: 0.6800 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1970 | loss: 0.6799 | Validation score: 0.5513 | Test score: 0.5960\n",
            "Epoch 1971 | loss: 0.6799 | Validation score: 0.5513 | Test score: 0.5960\n",
            "Epoch 1972 | loss: 0.6798 | Validation score: 0.5513 | Test score: 0.5960\n",
            "Epoch 1973 | loss: 0.6799 | Validation score: 0.5513 | Test score: 0.5956\n",
            "Epoch 1974 | loss: 0.6798 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1975 | loss: 0.6797 | Validation score: 0.5515 | Test score: 0.5960\n",
            "Epoch 1976 | loss: 0.6798 | Validation score: 0.5515 | Test score: 0.5964\n",
            "Epoch 1977 | loss: 0.6795 | Validation score: 0.5515 | Test score: 0.5964\n",
            "Epoch 1978 | loss: 0.6795 | Validation score: 0.5515 | Test score: 0.5964\n",
            "Epoch 1979 | loss: 0.6804 | Validation score: 0.5515 | Test score: 0.5964\n",
            "Epoch 1980 | loss: 0.6798 | Validation score: 0.5515 | Test score: 0.5964\n",
            "Epoch 1981 | loss: 0.6797 | Validation score: 0.5515 | Test score: 0.5964\n",
            "Epoch 1982 | loss: 0.6795 | Validation score: 0.5515 | Test score: 0.5956\n",
            "Epoch 1983 | loss: 0.6797 | Validation score: 0.5515 | Test score: 0.5956\n",
            "Epoch 1984 | loss: 0.6796 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1985 | loss: 0.6798 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1986 | loss: 0.6797 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1987 | loss: 0.6799 | Validation score: 0.5513 | Test score: 0.5956\n",
            "Epoch 1988 | loss: 0.6797 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1989 | loss: 0.6800 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1990 | loss: 0.6797 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1991 | loss: 0.6797 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1992 | loss: 0.6795 | Validation score: 0.5513 | Test score: 0.5956\n",
            "Epoch 1993 | loss: 0.6799 | Validation score: 0.5511 | Test score: 0.5956\n",
            "Epoch 1994 | loss: 0.6798 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1995 | loss: 0.6798 | Validation score: 0.5513 | Test score: 0.5960\n",
            "Epoch 1996 | loss: 0.6797 | Validation score: 0.5511 | Test score: 0.5960\n",
            "Epoch 1997 | loss: 0.6798 | Validation score: 0.5515 | Test score: 0.5960\n",
            "Epoch 1998 | loss: 0.6798 | Validation score: 0.5515 | Test score: 0.5960\n",
            "Epoch 1999 | loss: 0.6803 | Validation score: 0.5513 | Test score: 0.5960\n",
            "Epoch 2000 | loss: 0.6801 | Validation score: 0.5513 | Test score: 0.5960\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 2000\n",
        "report_frequency = len(X['train']) // batch_size // 5\n",
        "myloss=[]\n",
        "mytestaccuracy=[]\n",
        "myvalaccuracy=[]\n",
        "len_trainloader=len(train_loader)\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    avg_loss=0\n",
        "    for iteration, batch_idx in enumerate(train_loader):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        x_batch = X['train'][batch_idx]\n",
        "        y_batch = y['train'][batch_idx]\n",
        "        loss = loss_fn(apply_model(x_batch).squeeze(1), y_batch.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss += loss.item()\n",
        "    avg_loss=avg_loss / len_trainloader\n",
        "    myloss.append(avg_loss)\n",
        "    val_score = evaluate('val')\n",
        "    myvalaccuracy.append(val_score)\n",
        "    test_score = evaluate('test')\n",
        "    mytestaccuracy.append(test_score)\n",
        "    print(f'Epoch {epoch:03d} | loss: {avg_loss:.4f} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}')\n",
        "    # progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
        "    # if progress.success:\n",
        "    #     print(' <<< BEST VALIDATION EPOCH', end='')\n",
        "    # print()\n",
        "    # if progress.fail:\n",
        "    #     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DiZWST4IxEKd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "GJSkrpbMtPD5",
        "outputId": "a476600d-7734-4cfe-b2cf-9ec68a7de249"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "epoch_graph=np.arange(1,2001)\n",
        "\n",
        "plt.plot(epoch_graph,myloss)\n",
        "plt.title('training loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Training loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_graph,myvalaccuracy)\n",
        "plt.title('val accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_graph,mytestaccuracy)\n",
        "plt.title('test accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chFLu_FRyd7I"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled18.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3KA8A4C9HX3Dxn1y/ijBD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}